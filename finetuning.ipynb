{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2317f4be-aecd-40f6-9fb5-e3a59e3434bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from your local JSONL file using the full path\n",
    "dataset = load_dataset(\"json\", data_files=\"/Users/nafey/Desktop/domain_data.jsonl\")\n",
    "\n",
    "\n",
    "# Check the dataset's content\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb30fde7-f422-45db-86f5-15b333ef5c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2061, 318, 2199, 271, 38438, 30, 50256, 9771, 271, 38438, 318, 281, 13097, 9856, 13693, 326, 13692, 319, 38265, 2667, 262, 7625, 1022, 4569, 1524, 3707, 290, 6393, 1204, 4678, 13, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the GPT-2 tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Add pad token if not present\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"/Users/nafey/Desktop/domain_data.jsonl\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Concatenate prompt and completion for each example\n",
    "    prompts = examples[\"prompt\"]\n",
    "    completions = examples[\"completion\"]\n",
    "    \n",
    "    # Ensure both prompt and completion are lists of strings\n",
    "    inputs = [prompt + tokenizer.eos_token + completion for prompt, completion in zip(prompts, completions)]\n",
    "    \n",
    "    # Tokenize with padding and truncation\n",
    "    encoding = tokenizer(inputs, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\")\n",
    "    \n",
    "    # Return the tokenized data (input_ids and attention_mask should now be tensors)\n",
    "    return encoding\n",
    "\n",
    "# Apply tokenization in batches\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"prompt\", \"completion\"])\n",
    "\n",
    "# Check the tokenized dataset\n",
    "print(tokenized_dataset['train'][0])  # Check the first example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbeb1dcd-da86-48ab-af3a-e8889f12622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2061, 318, 2199, 271, 38438, 30, 50256, 9771, 271, 38438, 318, 281, 13097, 9856, 13693, 326, 13692, 319, 38265, 2667, 262, 7625, 1022, 4569, 1524, 3707, 290, 6393, 1204, 4678, 13, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e43749-e5ff-4ed6-87ad-897dc717fe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 14\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask'],\n",
      "        num_rows: 3\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Assuming you have already tokenized the dataset and stored it in `tokenized_dataset`\n",
    "\n",
    "# Manually split the 'train' data into train, validation, and test sets\n",
    "train_dataset = tokenized_dataset[\"train\"].select(range(0, 14))  # 70% for training\n",
    "val_dataset = tokenized_dataset[\"train\"].select(range(14, 17))   # 15% for validation\n",
    "test_dataset = tokenized_dataset[\"train\"].select(range(17, 20))  # 15% for testing\n",
    "\n",
    "# Create a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Print the resulting DatasetDict\n",
    "print(split_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fab555-dc0b-4b1b-9f81-eabd2e225cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d43ec22-a83a-4c1c-97c7-36c7c03a1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"gpt2\"  # Replace with your desired model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# Add pad token to the model's configuration if it's not already present\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4157bda1-343d-4d13-b063-38d29e603c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67b14ec74aa4748874ba0e65c1f6e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6bb6bb5824416985cd4a35b729c9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2061, 318, 9552, 30, 50256, 20185, 6296, 329, 35941, 9345, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2061, 318, 262, 3139, 286, 4881, 30, 50256, 464, 3139, 286, 4881, 318, 6342, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': [2061, 318, 11361, 30, 50256, 37906, 318, 257, 8300, 3303, 13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ -37.2173,  -36.8865,  -40.3564,  ...,  -43.4352,  -43.0233,\n",
      "           -37.0995],\n",
      "         [ -84.7417,  -82.6453,  -88.2857,  ...,  -89.4500,  -90.0554,\n",
      "           -84.6770],\n",
      "         [ -74.2669,  -71.7886,  -76.2888,  ...,  -81.3937,  -81.2737,\n",
      "           -75.6428],\n",
      "         ...,\n",
      "         [ -93.5482,  -86.0402,  -89.0368,  ..., -106.4046, -107.0581,\n",
      "           -95.0270],\n",
      "         [ -93.5502,  -86.0450,  -89.0387,  ..., -106.4041, -107.0583,\n",
      "           -95.0266],\n",
      "         [ -93.6264,  -86.1196,  -89.1128,  ..., -106.4893, -107.1437,\n",
      "           -95.1024]]], grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-1.3190e+00,  1.8644e+00,  8.9757e-01,  ..., -1.4033e+00,\n",
      "           -2.3651e-01,  1.2896e+00],\n",
      "          [-1.8348e+00,  2.4955e+00,  1.7497e+00,  ..., -1.5397e+00,\n",
      "           -2.3685e+00,  2.4482e+00],\n",
      "          [-2.1391e+00,  3.5105e+00,  2.3078e+00,  ...,  2.7298e-01,\n",
      "           -2.2373e+00,  8.6389e-01],\n",
      "          ...,\n",
      "          [ 1.2912e+00,  3.3687e-01,  3.0991e+00,  ..., -1.9983e+00,\n",
      "            5.5623e-01,  2.9517e-01],\n",
      "          [ 1.3109e+00,  3.3783e-01,  3.0332e+00,  ..., -1.9603e+00,\n",
      "            5.8812e-01,  2.1151e-01],\n",
      "          [ 1.3231e+00,  3.1822e-01,  3.0527e+00,  ..., -1.9550e+00,\n",
      "            5.5717e-01,  2.6986e-01]],\n",
      "\n",
      "         [[-3.7719e-01,  4.4023e-01, -6.4755e-01,  ..., -3.9102e-01,\n",
      "            2.5417e+00,  1.0485e+00],\n",
      "          [ 6.7388e-01, -1.3429e+00, -1.0824e-01,  ..., -3.4649e+00,\n",
      "            3.4113e+00,  9.9918e-01],\n",
      "          [ 9.2376e-01, -9.9824e-01, -5.1016e-01,  ..., -7.0625e-01,\n",
      "            2.6272e+00, -2.7318e-01],\n",
      "          ...,\n",
      "          [-8.2024e-01,  2.2217e+00, -1.5488e+00,  ...,  1.3847e+00,\n",
      "           -6.5690e-01,  4.7188e-01],\n",
      "          [-8.2295e-01,  2.2170e+00, -1.5483e+00,  ...,  1.3967e+00,\n",
      "           -6.9180e-01,  4.6501e-01],\n",
      "          [-8.3317e-01,  2.2352e+00, -1.5474e+00,  ...,  1.4173e+00,\n",
      "           -6.8438e-01,  4.3730e-01]],\n",
      "\n",
      "         [[ 2.2048e-02, -7.5673e-02,  8.3024e-01,  ..., -1.4517e+00,\n",
      "           -1.6848e+00,  8.1629e-01],\n",
      "          [ 4.3450e-01,  2.0733e-01,  3.2424e-01,  ..., -2.4565e+00,\n",
      "            1.1946e-01,  1.9386e+00],\n",
      "          [ 2.0451e+00,  1.4099e+00, -1.2403e+00,  ..., -2.7780e+00,\n",
      "           -6.5809e-01,  2.6717e-01],\n",
      "          ...,\n",
      "          [-8.4253e-01,  1.2516e+00,  3.3574e-01,  ...,  8.3568e-01,\n",
      "            2.5109e-03, -4.3672e-01],\n",
      "          [-8.6977e-01,  1.2556e+00,  3.3365e-01,  ...,  8.3739e-01,\n",
      "           -1.3162e-02, -4.2354e-01],\n",
      "          [-8.5788e-01,  1.2379e+00,  3.5623e-01,  ...,  8.4428e-01,\n",
      "           -5.1728e-02, -4.2150e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3110e-01, -4.6927e-02, -1.3321e-01,  ...,  3.7510e-01,\n",
      "            6.8562e-01,  5.7607e-01],\n",
      "          [ 2.5121e-01,  1.1030e-01, -2.8209e-02,  ...,  8.2454e-01,\n",
      "            3.1058e-01,  5.9335e-01],\n",
      "          [-4.4781e-01,  2.4432e-01, -3.7286e-01,  ...,  1.1074e+00,\n",
      "           -3.5359e-01,  7.3344e-02],\n",
      "          ...,\n",
      "          [-1.1966e-01,  3.8408e-01, -4.0073e-02,  ...,  3.7845e-01,\n",
      "           -4.1502e-01,  2.5866e-01],\n",
      "          [-9.9488e-02,  3.5849e-01, -3.3366e-02,  ...,  3.6360e-01,\n",
      "           -4.0198e-01,  2.5298e-01],\n",
      "          [-1.3287e-01,  3.9459e-01, -1.7719e-02,  ...,  3.6601e-01,\n",
      "           -4.1567e-01,  2.5341e-01]],\n",
      "\n",
      "         [[ 1.4246e+00,  1.3487e+00, -2.4757e-01,  ..., -2.8181e-01,\n",
      "            9.5264e-01, -1.1325e+00],\n",
      "          [ 8.5059e-01,  6.2667e-01, -7.5365e-01,  ..., -9.0627e-01,\n",
      "            8.3284e-01, -5.7886e-01],\n",
      "          [ 2.0978e+00, -2.3494e-01, -7.8207e-01,  ..., -1.1640e+00,\n",
      "            1.0537e+00, -7.9750e-01],\n",
      "          ...,\n",
      "          [-6.9685e-02,  3.4072e-01,  8.3002e-01,  ..., -1.5004e+00,\n",
      "            1.0308e+00, -8.4910e-01],\n",
      "          [-7.0348e-02,  3.6484e-01,  8.3010e-01,  ..., -1.4894e+00,\n",
      "            1.0467e+00, -8.6616e-01],\n",
      "          [-6.9420e-02,  3.6986e-01,  8.5219e-01,  ..., -1.5080e+00,\n",
      "            1.0622e+00, -8.7780e-01]],\n",
      "\n",
      "         [[ 4.9501e-01,  2.0561e-01, -7.4766e-02,  ..., -3.4694e-01,\n",
      "            1.5860e-01,  1.7998e+00],\n",
      "          [ 1.2434e+00,  6.7664e-02,  6.1694e-02,  ...,  7.0984e-01,\n",
      "            5.2591e-01,  1.7975e+00],\n",
      "          [-2.0525e-01,  3.3899e-01, -3.4859e-01,  ..., -8.1221e-01,\n",
      "            8.6506e-02,  1.3123e+00],\n",
      "          ...,\n",
      "          [ 1.2917e-01, -9.1561e-01, -9.2725e-01,  ..., -2.3148e+00,\n",
      "           -3.0815e-02, -9.1642e-01],\n",
      "          [ 1.5302e-01, -9.1169e-01, -9.1907e-01,  ..., -2.3070e+00,\n",
      "           -3.0640e-02, -8.9679e-01],\n",
      "          [ 1.4192e-01, -9.2267e-01, -9.3864e-01,  ..., -2.2831e+00,\n",
      "           -1.7149e-02, -9.2865e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 2.3089e-02,  8.2066e-02,  2.7945e-02,  ...,  2.6097e-02,\n",
      "           -2.3956e-02,  9.6702e-02],\n",
      "          [ 2.3196e-01, -2.3861e-01,  2.9457e-01,  ..., -5.8200e-02,\n",
      "            7.4808e-02, -8.7832e-02],\n",
      "          [-8.2540e-02,  1.3078e-02, -1.6693e-01,  ...,  1.2496e-01,\n",
      "           -6.4541e-03,  1.3579e-01],\n",
      "          ...,\n",
      "          [ 4.0512e-02,  1.0918e-01, -2.5791e-01,  ...,  2.4008e-02,\n",
      "            4.0356e-01,  1.5694e-01],\n",
      "          [ 3.1691e-02,  1.0404e-01, -2.5556e-01,  ...,  2.4194e-02,\n",
      "            3.9569e-01,  1.5879e-01],\n",
      "          [ 3.2822e-02,  1.1451e-01, -2.5818e-01,  ...,  2.2927e-02,\n",
      "            3.9933e-01,  1.5661e-01]],\n",
      "\n",
      "         [[ 4.7284e-01,  1.1574e-01, -2.9770e-01,  ..., -6.3272e-01,\n",
      "           -2.1164e-01,  1.9056e-01],\n",
      "          [ 5.5125e-01,  7.0201e-02,  1.0743e-01,  ...,  1.1353e-02,\n",
      "            2.2987e-01, -7.8098e-02],\n",
      "          [ 1.5916e-01, -3.3740e-01,  2.7692e-01,  ..., -1.6063e-02,\n",
      "            2.8543e-01,  1.7485e-01],\n",
      "          ...,\n",
      "          [ 3.3357e-01,  3.0897e-02,  3.5616e-02,  ..., -1.2724e-01,\n",
      "            4.8958e-01,  1.3043e-01],\n",
      "          [ 3.4069e-01,  3.5078e-02,  3.1255e-02,  ..., -1.3189e-01,\n",
      "            4.8984e-01,  1.3277e-01],\n",
      "          [ 3.6333e-01,  2.2490e-02,  3.2792e-02,  ..., -1.3943e-01,\n",
      "            4.9507e-01,  1.3159e-01]],\n",
      "\n",
      "         [[ 7.3907e-02, -1.1804e-01,  8.6928e-02,  ..., -7.0653e-03,\n",
      "           -1.7058e-04, -6.2187e-02],\n",
      "          [ 9.5054e-02,  9.0989e-02,  5.3470e-02,  ..., -2.7077e-02,\n",
      "            9.1225e-02,  1.0601e-01],\n",
      "          [ 1.8979e-01,  1.7034e-01,  2.3530e-02,  ..., -1.8382e-01,\n",
      "           -4.4473e-02,  2.0551e-01],\n",
      "          ...,\n",
      "          [-2.1788e-01, -1.9669e-01,  5.6261e-01,  ..., -1.8748e-02,\n",
      "            1.8847e-01, -2.4832e-01],\n",
      "          [-2.1442e-01, -1.9817e-01,  5.6282e-01,  ..., -2.8999e-02,\n",
      "            1.8887e-01, -2.4760e-01],\n",
      "          [-2.1074e-01, -1.9237e-01,  5.6270e-01,  ..., -3.3232e-02,\n",
      "            1.8775e-01, -2.4936e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.8233e-02,  7.8248e-02,  8.7423e-02,  ..., -1.5830e-01,\n",
      "            8.4335e-02, -6.9996e-02],\n",
      "          [-4.7730e-01,  5.3618e-01,  1.1470e-01,  ...,  2.1382e-01,\n",
      "           -4.0779e-01,  1.0846e-01],\n",
      "          [-5.1173e-02,  4.2402e-01,  3.7369e-01,  ...,  1.3504e-01,\n",
      "            1.0623e-01,  2.0570e-01],\n",
      "          ...,\n",
      "          [-2.6009e-03, -3.4872e-01,  6.5507e-02,  ...,  4.5521e-02,\n",
      "            3.3931e-02, -9.9467e-02],\n",
      "          [-7.4124e-03, -3.4590e-01,  6.8146e-02,  ...,  5.2559e-02,\n",
      "            3.2472e-02, -1.0320e-01],\n",
      "          [-4.6801e-03, -3.4766e-01,  6.6034e-02,  ...,  4.2373e-02,\n",
      "            3.5850e-02, -1.0955e-01]],\n",
      "\n",
      "         [[ 1.7370e-02, -8.3901e-02, -2.1068e-01,  ...,  1.3147e-01,\n",
      "            2.3579e-01, -4.4249e-02],\n",
      "          [-3.5043e-01,  7.0391e-02,  2.1141e-01,  ..., -6.4529e-01,\n",
      "           -1.4333e-01,  8.3923e-02],\n",
      "          [-5.9407e-02,  1.3599e-01, -8.0328e-02,  ..., -1.8744e-01,\n",
      "           -3.9726e-02, -1.2967e-03],\n",
      "          ...,\n",
      "          [-1.8292e-01, -2.8228e-01, -1.5192e-01,  ..., -6.2917e-02,\n",
      "            5.5009e-01,  1.8883e-01],\n",
      "          [-1.7721e-01, -2.8351e-01, -1.5899e-01,  ..., -7.5442e-02,\n",
      "            5.4811e-01,  1.7844e-01],\n",
      "          [-1.7495e-01, -2.8418e-01, -1.5849e-01,  ..., -6.1480e-02,\n",
      "            5.4990e-01,  1.8222e-01]],\n",
      "\n",
      "         [[ 7.5052e-02, -4.4470e-01,  1.6571e-01,  ...,  7.0883e-03,\n",
      "           -2.7171e-01, -8.7654e-02],\n",
      "          [-5.8485e-02, -1.2240e-02, -3.8542e-02,  ...,  1.7494e-01,\n",
      "            3.7288e-01,  1.2658e-01],\n",
      "          [-2.1632e-02,  7.4889e-02, -4.0594e-01,  ...,  1.6316e-01,\n",
      "           -2.1139e-01,  1.1147e-01],\n",
      "          ...,\n",
      "          [ 2.5217e-01, -6.2311e-01, -4.6525e-01,  ...,  3.4742e-01,\n",
      "           -5.5867e-01,  4.0953e-01],\n",
      "          [ 2.5030e-01, -6.2878e-01, -4.6575e-01,  ...,  3.5576e-01,\n",
      "           -5.5846e-01,  4.0838e-01],\n",
      "          [ 2.5197e-01, -6.2556e-01, -4.6459e-01,  ...,  3.5275e-01,\n",
      "           -5.7518e-01,  4.1371e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1547,  1.6268, -1.8836,  ...,  1.4842, -1.3666,  0.2139],\n",
      "          [ 0.9715,  2.6372, -1.7462,  ..., -0.6044, -2.1933,  0.4020],\n",
      "          [-0.4057,  1.3454, -0.5188,  ..., -0.7952, -1.7945, -1.1955],\n",
      "          ...,\n",
      "          [ 1.4521, -0.4684,  0.4192,  ..., -2.9300, -0.8961,  0.9391],\n",
      "          [ 1.4702, -0.4661,  0.4209,  ..., -2.9119, -0.9247,  0.9264],\n",
      "          [ 1.4876, -0.4855,  0.4171,  ..., -2.9013, -0.9223,  0.9153]],\n",
      "\n",
      "         [[-0.9370, -0.2726, -0.5719,  ..., -0.0903,  0.5231, -0.8064],\n",
      "          [-0.5968,  0.3361, -1.4138,  ..., -0.7028,  0.5123, -0.3127],\n",
      "          [-0.2254, -0.3221, -1.1442,  ..., -0.3701, -0.0387, -0.8602],\n",
      "          ...,\n",
      "          [ 0.0749,  0.8602,  2.3115,  ..., -1.3973, -1.1947,  1.0525],\n",
      "          [ 0.0708,  0.8572,  2.3138,  ..., -1.3929, -1.1969,  1.0254],\n",
      "          [ 0.0811,  0.8473,  2.3287,  ..., -1.3983, -1.1969,  1.0167]],\n",
      "\n",
      "         [[ 0.5172,  0.0165, -0.0691,  ..., -1.3421,  0.0987, -0.3519],\n",
      "          [-0.1099,  0.1366, -0.1238,  ..., -1.0395, -0.1675,  0.3408],\n",
      "          [ 0.0299,  0.3016, -0.4060,  ..., -0.9646, -0.3356,  0.1568],\n",
      "          ...,\n",
      "          [-0.5594,  0.2756,  0.3975,  ...,  0.1393, -0.0687,  0.2245],\n",
      "          [-0.5571,  0.2769,  0.3936,  ...,  0.1309, -0.0717,  0.2245],\n",
      "          [-0.5581,  0.2760,  0.3933,  ...,  0.1202, -0.0700,  0.2235]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0222, -0.8542, -0.7293,  ..., -1.0152,  0.7217, -0.7865],\n",
      "          [-0.1887,  2.2690,  1.4309,  ..., -0.0890, -0.2236, -0.0060],\n",
      "          [-0.5567, -0.0133,  1.9220,  ...,  1.6043, -0.3331, -0.6513],\n",
      "          ...,\n",
      "          [-1.6873,  0.5599,  0.4046,  ..., -0.4031, -0.7756,  1.6338],\n",
      "          [-1.6807,  0.5628,  0.4278,  ..., -0.4016, -0.7721,  1.6282],\n",
      "          [-1.6855,  0.5715,  0.4346,  ..., -0.3973, -0.7976,  1.6388]],\n",
      "\n",
      "         [[-1.1444, -2.9872,  0.1738,  ...,  1.7588,  1.6085, -1.3629],\n",
      "          [ 0.1711,  0.9862, -0.4783,  ..., -0.9182,  0.5088, -0.4740],\n",
      "          [ 0.2237,  0.7679, -0.4769,  ..., -0.8454,  0.6564, -0.0499],\n",
      "          ...,\n",
      "          [ 0.2117,  0.3306,  0.4279,  ..., -0.2748,  0.0531,  0.5943],\n",
      "          [ 0.2089,  0.3265,  0.4115,  ..., -0.2732,  0.0452,  0.5975],\n",
      "          [ 0.2129,  0.3304,  0.3995,  ..., -0.2748,  0.0331,  0.6009]],\n",
      "\n",
      "         [[ 0.9307,  2.5125,  0.5301,  ..., -0.6137, -0.5969,  0.8741],\n",
      "          [ 1.1523,  1.9405, -0.3564,  ...,  1.1550,  0.1263, -1.1208],\n",
      "          [-0.0339,  1.8744,  1.1167,  ...,  1.7115, -0.0897, -1.6130],\n",
      "          ...,\n",
      "          [-0.7300,  1.3970, -0.5239,  ..., -1.4077,  0.7412, -0.3987],\n",
      "          [-0.7155,  1.4138, -0.5183,  ..., -1.3949,  0.7373, -0.3985],\n",
      "          [-0.7239,  1.4040, -0.5196,  ..., -1.3883,  0.7412, -0.3971]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 6.8883e-01, -1.2200e-01,  5.8287e-02,  ..., -1.6138e-01,\n",
      "           -5.1933e-02, -6.8165e-02],\n",
      "          [ 1.1373e-01,  1.2317e-01, -1.2735e-01,  ..., -2.5363e-01,\n",
      "           -3.8141e-01, -3.0041e-02],\n",
      "          [ 6.2750e-02,  3.3331e-01, -2.9796e-01,  ...,  2.8646e-01,\n",
      "           -3.8942e-01, -6.2006e-01],\n",
      "          ...,\n",
      "          [ 4.7021e-01, -1.2820e-01,  8.8341e-02,  ...,  1.5691e-01,\n",
      "           -1.9438e-01, -1.4522e-01],\n",
      "          [ 4.7252e-01, -1.2850e-01,  9.1065e-02,  ...,  1.5762e-01,\n",
      "           -1.9483e-01, -1.4218e-01],\n",
      "          [ 4.7264e-01, -1.2980e-01,  9.2942e-02,  ...,  1.5836e-01,\n",
      "           -1.9357e-01, -1.4442e-01]],\n",
      "\n",
      "         [[ 2.8172e-01, -1.4177e-01, -3.3247e-02,  ..., -4.2517e-03,\n",
      "           -6.2682e-01, -1.6292e-01],\n",
      "          [ 8.6475e-02,  4.7631e-01,  8.2816e-01,  ..., -3.3462e-01,\n",
      "            1.6736e-01,  3.7501e-01],\n",
      "          [-1.2837e-01,  3.2494e-01,  5.2653e-01,  ...,  5.5185e-01,\n",
      "            9.0510e-02, -3.5867e-01],\n",
      "          ...,\n",
      "          [ 2.5091e-01,  2.7319e-02,  1.1159e-01,  ..., -2.6222e-01,\n",
      "            2.3824e-01, -2.1554e-01],\n",
      "          [ 2.5459e-01,  2.2930e-02,  1.1722e-01,  ..., -2.6089e-01,\n",
      "            2.2972e-01, -2.1194e-01],\n",
      "          [ 2.5368e-01,  2.1659e-02,  1.1484e-01,  ..., -2.5595e-01,\n",
      "            2.2879e-01, -2.1445e-01]],\n",
      "\n",
      "         [[ 7.5605e-02, -1.9960e-01,  2.2040e-01,  ..., -6.0181e-01,\n",
      "            2.5395e-01,  3.7750e-02],\n",
      "          [ 4.8986e-01,  2.6058e-01,  4.7339e-01,  ..., -7.1976e-01,\n",
      "            1.0688e-02,  9.9028e-02],\n",
      "          [ 4.2733e-01,  4.1290e-01, -2.0004e-01,  ..., -7.2667e-01,\n",
      "            3.0678e-03, -3.7993e-01],\n",
      "          ...,\n",
      "          [-7.5388e-01, -2.2093e-01,  8.1878e-02,  ..., -1.6257e-01,\n",
      "           -1.8698e-01, -4.8545e-01],\n",
      "          [-7.2955e-01, -2.1787e-01,  8.2767e-02,  ..., -1.9518e-01,\n",
      "           -1.8780e-01, -4.7680e-01],\n",
      "          [-7.1594e-01, -2.2123e-01,  8.4818e-02,  ..., -2.1326e-01,\n",
      "           -1.8568e-01, -4.7989e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7756e-01,  7.3150e-01, -1.1882e-01,  ...,  9.4002e-02,\n",
      "           -1.0455e+00, -1.3381e-01],\n",
      "          [ 3.2840e-02, -1.5387e-01, -5.8459e-02,  ..., -3.5557e-02,\n",
      "           -4.0062e-01, -3.7858e-01],\n",
      "          [-1.3607e-01,  1.6859e-01,  2.6587e-01,  ...,  4.1761e-01,\n",
      "           -4.2100e-01,  2.8346e-01],\n",
      "          ...,\n",
      "          [ 1.4855e-01, -5.5713e-01,  4.6725e-01,  ..., -9.7032e-01,\n",
      "           -4.7044e-01, -5.7806e-01],\n",
      "          [ 1.5321e-01, -5.6153e-01,  4.6820e-01,  ..., -9.7019e-01,\n",
      "           -4.7036e-01, -5.7429e-01],\n",
      "          [ 1.5888e-01, -5.6923e-01,  4.7109e-01,  ..., -9.7383e-01,\n",
      "           -4.7531e-01, -5.7749e-01]],\n",
      "\n",
      "         [[ 3.3763e-01, -2.0805e-01, -3.4444e-01,  ...,  2.3931e-01,\n",
      "           -3.6649e+00,  2.3963e-02],\n",
      "          [ 9.0235e-02, -1.0785e-01,  2.6493e-01,  ...,  5.3018e-01,\n",
      "            1.3830e-01, -2.3809e-02],\n",
      "          [-2.0692e-01,  6.0090e-01, -5.5289e-02,  ..., -2.3577e-02,\n",
      "            6.1515e-02, -2.2018e-01],\n",
      "          ...,\n",
      "          [ 1.9852e-01,  1.1796e-01,  1.1352e+00,  ..., -4.4846e-01,\n",
      "            4.4605e-01, -9.1755e-01],\n",
      "          [ 1.9983e-01,  1.1266e-01,  1.1365e+00,  ..., -4.4418e-01,\n",
      "            4.5162e-01, -9.1876e-01],\n",
      "          [ 1.9946e-01,  1.1668e-01,  1.1397e+00,  ..., -4.4262e-01,\n",
      "            4.5214e-01, -9.2009e-01]],\n",
      "\n",
      "         [[ 3.9806e-02, -1.4273e-01, -3.9806e-02,  ..., -1.9534e-01,\n",
      "            2.2148e-01, -8.1456e-02],\n",
      "          [ 9.1554e-02, -5.5453e-02, -1.9582e-01,  ...,  7.3032e-03,\n",
      "            3.7519e-01,  1.1371e-01],\n",
      "          [-3.7569e-01,  4.3108e-01,  2.7888e-01,  ..., -1.5127e-01,\n",
      "            2.3457e-01,  5.7859e-02],\n",
      "          ...,\n",
      "          [-2.1145e-01,  2.5522e-01,  7.6897e-01,  ...,  7.6788e-02,\n",
      "            3.8892e-01, -1.4121e-01],\n",
      "          [-2.0970e-01,  2.5229e-01,  7.6863e-01,  ...,  7.6854e-02,\n",
      "            3.8618e-01, -1.4629e-01],\n",
      "          [-2.0498e-01,  2.5171e-01,  7.6455e-01,  ...,  7.8513e-02,\n",
      "            3.8339e-01, -1.4438e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.3064e-01, -1.0979e+00,  3.2432e-01,  ..., -6.3491e-01,\n",
      "           -1.5534e-01, -3.2244e-02],\n",
      "          [ 9.1356e-01, -1.9732e+00, -1.5342e+00,  ..., -4.0318e-01,\n",
      "            6.9114e-01, -2.0584e+00],\n",
      "          [ 4.9046e-01, -2.8478e+00,  7.8630e-01,  ..., -1.0806e+00,\n",
      "            5.4401e-01, -5.9499e-02],\n",
      "          ...,\n",
      "          [-1.7692e-01, -7.7054e-02,  7.9683e-01,  ..., -1.8936e-01,\n",
      "            3.5597e-01,  5.0646e-02],\n",
      "          [-1.7555e-01, -7.4985e-02,  7.9651e-01,  ..., -1.7939e-01,\n",
      "            3.5792e-01,  4.7444e-02],\n",
      "          [-1.7336e-01, -7.1270e-02,  7.9798e-01,  ..., -1.6907e-01,\n",
      "            3.5657e-01,  4.9813e-02]],\n",
      "\n",
      "         [[-5.1276e-01,  2.7388e-01, -4.6331e-01,  ...,  1.2137e+00,\n",
      "           -5.0740e-01, -4.4837e-01],\n",
      "          [-1.1845e+00,  2.5825e-03, -2.0988e+00,  ...,  7.7741e-01,\n",
      "            1.1046e+00, -4.0853e-01],\n",
      "          [-2.7508e+00, -6.4462e-01, -3.8062e-01,  ..., -9.6991e-01,\n",
      "           -1.1074e+00,  5.5223e-02],\n",
      "          ...,\n",
      "          [-2.1351e+00, -1.4016e+00, -1.8903e+00,  ...,  1.1356e-01,\n",
      "            2.4390e-01, -1.5618e+00],\n",
      "          [-2.1469e+00, -1.4096e+00, -1.8879e+00,  ...,  1.0560e-01,\n",
      "            2.4962e-01, -1.5620e+00],\n",
      "          [-2.1358e+00, -1.4044e+00, -1.8818e+00,  ...,  1.1146e-01,\n",
      "            2.5334e-01, -1.5570e+00]],\n",
      "\n",
      "         [[ 1.2301e+00,  3.0167e+00,  3.7457e+00,  ...,  6.4829e-01,\n",
      "            1.6559e+00, -7.5835e-01],\n",
      "          [-3.5332e+00,  2.7201e+00, -3.1271e+00,  ..., -2.3347e+00,\n",
      "            3.7236e+00,  1.3975e+00],\n",
      "          [-3.1056e+00,  7.4126e-01, -3.3847e+00,  ..., -3.1660e+00,\n",
      "            3.0075e+00,  8.5790e-01],\n",
      "          ...,\n",
      "          [-3.9335e+00, -1.0199e+00, -3.3532e+00,  ...,  1.2781e+00,\n",
      "            1.0071e+00,  6.9962e-01],\n",
      "          [-3.9627e+00, -1.0274e+00, -3.4042e+00,  ...,  1.2560e+00,\n",
      "            1.0110e+00,  6.6392e-01],\n",
      "          [-3.9736e+00, -1.0390e+00, -3.4317e+00,  ...,  1.2417e+00,\n",
      "            1.0193e+00,  6.3146e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3653e+00, -2.7223e+00, -2.6976e+00,  ...,  9.1960e-01,\n",
      "            4.5927e-01,  2.6761e+00],\n",
      "          [-1.8721e+00,  2.2937e+00,  6.3503e-01,  ..., -5.0201e-01,\n",
      "           -2.4214e+00,  1.9656e-01],\n",
      "          [-2.3124e+00,  1.5516e+00,  7.5686e-01,  ...,  4.7144e-01,\n",
      "           -1.7371e+00, -2.2995e-01],\n",
      "          ...,\n",
      "          [-1.0002e+00,  3.1144e+00,  2.4838e+00,  ..., -2.5144e-01,\n",
      "            1.7398e-01, -3.1211e+00],\n",
      "          [-1.0004e+00,  3.1561e+00,  2.5023e+00,  ..., -2.5854e-01,\n",
      "            1.8396e-01, -3.1178e+00],\n",
      "          [-9.9630e-01,  3.1853e+00,  2.5166e+00,  ..., -2.6984e-01,\n",
      "            1.9133e-01, -3.1118e+00]],\n",
      "\n",
      "         [[ 1.7415e+00,  4.4209e-01,  9.3136e-01,  ..., -2.7852e-03,\n",
      "           -9.8478e-01, -3.0201e-01],\n",
      "          [ 1.9936e+00,  1.1219e+00,  6.8835e-01,  ...,  3.0822e-02,\n",
      "           -1.7473e+00, -1.4582e+00],\n",
      "          [ 2.4431e+00,  3.4161e-01,  1.5607e+00,  ...,  7.6540e-02,\n",
      "           -1.2234e+00, -1.2997e+00],\n",
      "          ...,\n",
      "          [-7.8451e-02,  5.3838e-01,  1.7024e-01,  ...,  3.9750e-01,\n",
      "            9.4971e-01, -5.3005e-01],\n",
      "          [-8.2288e-02,  5.3910e-01,  1.7188e-01,  ...,  3.9302e-01,\n",
      "            9.6125e-01, -5.2798e-01],\n",
      "          [-8.9390e-02,  5.4069e-01,  1.7102e-01,  ...,  3.9233e-01,\n",
      "            9.7236e-01, -5.2578e-01]],\n",
      "\n",
      "         [[-2.6355e-01,  1.7693e-01, -5.4590e-01,  ...,  2.5397e-01,\n",
      "            2.7925e-01,  1.6319e-01],\n",
      "          [-9.4149e-01,  7.3126e-01,  1.2778e-01,  ..., -3.4195e-02,\n",
      "            7.7102e-01, -2.5772e-01],\n",
      "          [-2.1419e-01,  5.0077e-01, -2.2333e-01,  ..., -4.2888e-01,\n",
      "            2.2202e-01, -2.3712e-01],\n",
      "          ...,\n",
      "          [-1.2031e+00, -9.9422e-02, -4.3896e-01,  ...,  8.8427e-01,\n",
      "            2.4477e-01,  1.3355e+00],\n",
      "          [-1.2062e+00, -1.0205e-01, -4.3674e-01,  ...,  8.8222e-01,\n",
      "            2.4546e-01,  1.3353e+00],\n",
      "          [-1.2077e+00, -1.0306e-01, -4.3670e-01,  ...,  8.7823e-01,\n",
      "            2.4434e-01,  1.3358e+00]]]], grad_fn=<PermuteBackward0>), tensor([[[[-5.0380e-04,  4.8796e-03, -1.4501e-01,  ..., -7.6290e-03,\n",
      "           -2.8119e-02, -5.4427e-01],\n",
      "          [ 4.1592e-01, -1.6358e-01, -6.1516e-01,  ..., -1.1610e+00,\n",
      "           -3.3906e-01,  7.3473e-01],\n",
      "          [ 1.4896e-01, -4.5920e-01,  6.3605e-02,  ...,  8.4951e-02,\n",
      "            1.7457e-01,  6.2730e-01],\n",
      "          ...,\n",
      "          [ 5.2338e-01,  1.4564e+00, -7.3620e-01,  ..., -2.1799e-01,\n",
      "           -2.1942e-01, -6.1960e-01],\n",
      "          [ 5.2035e-01,  1.4544e+00, -7.3577e-01,  ..., -2.2016e-01,\n",
      "           -2.2012e-01, -6.2141e-01],\n",
      "          [ 5.2096e-01,  1.4569e+00, -7.3717e-01,  ..., -2.1875e-01,\n",
      "           -2.2603e-01, -6.2350e-01]],\n",
      "\n",
      "         [[ 3.9716e-02,  1.0030e-02,  3.6718e-02,  ..., -4.8265e-02,\n",
      "           -3.5170e-03,  1.6775e-02],\n",
      "          [-1.1896e-01,  1.7423e-01,  1.9564e-02,  ..., -6.3828e-01,\n",
      "            1.1594e-01, -1.3074e-01],\n",
      "          [ 1.8493e-01,  2.9609e-01,  9.6181e-02,  ...,  2.6727e-01,\n",
      "           -1.9976e-01, -6.4473e-01],\n",
      "          ...,\n",
      "          [ 3.4487e-01, -2.7845e-01, -1.8709e-01,  ..., -1.7969e-02,\n",
      "            3.2006e-01,  1.4830e-01],\n",
      "          [ 3.4264e-01, -2.7760e-01, -1.8944e-01,  ..., -1.9577e-02,\n",
      "            3.1833e-01,  1.4786e-01],\n",
      "          [ 3.4253e-01, -2.7653e-01, -1.9311e-01,  ..., -2.2295e-02,\n",
      "            3.1681e-01,  1.4497e-01]],\n",
      "\n",
      "         [[ 3.3389e-02, -7.5867e-01, -7.8789e-02,  ...,  5.0789e-02,\n",
      "            6.6967e-03, -5.6933e-02],\n",
      "          [ 1.8743e-01, -8.2430e-01,  1.6054e-01,  ...,  5.8465e-01,\n",
      "           -3.7226e-01,  4.5724e-01],\n",
      "          [ 4.9774e-01, -9.9243e-01,  1.0944e-01,  ...,  3.1350e-01,\n",
      "            1.1635e-01, -5.4695e-01],\n",
      "          ...,\n",
      "          [ 1.1099e-01, -1.4266e+00,  1.3608e-02,  ...,  3.8142e-02,\n",
      "           -4.8527e-02, -2.0384e-01],\n",
      "          [ 1.0809e-01, -1.4260e+00,  1.3667e-02,  ...,  4.2250e-02,\n",
      "           -4.7814e-02, -2.0519e-01],\n",
      "          [ 1.0914e-01, -1.4272e+00,  1.5064e-02,  ...,  4.0634e-02,\n",
      "           -4.6653e-02, -2.0444e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6744e-02, -7.3889e-02,  1.3169e+00,  ..., -4.2897e-02,\n",
      "            1.9233e-01, -2.8341e-02],\n",
      "          [ 1.1231e-01, -5.2662e-01,  2.1252e+00,  ...,  4.1341e-01,\n",
      "            1.5472e-01,  4.6660e-01],\n",
      "          [ 3.0169e-03, -1.1599e-01,  3.6330e-01,  ...,  1.2569e-01,\n",
      "           -4.5832e-01,  1.4389e-01],\n",
      "          ...,\n",
      "          [-1.8472e-01, -3.4743e-02,  2.0090e+00,  ...,  2.0087e-01,\n",
      "            1.0267e-02,  1.5631e-01],\n",
      "          [-1.8302e-01, -3.3781e-02,  2.0116e+00,  ...,  2.0014e-01,\n",
      "            1.0415e-02,  1.5629e-01],\n",
      "          [-1.7948e-01, -3.0916e-02,  2.0099e+00,  ...,  2.0121e-01,\n",
      "            1.1571e-02,  1.5293e-01]],\n",
      "\n",
      "         [[ 3.3705e-03, -1.1483e-01, -1.7243e-01,  ...,  1.5501e-01,\n",
      "            1.0659e-01,  1.5490e-01],\n",
      "          [ 7.2209e-01, -7.6461e-02, -4.1955e-01,  ...,  8.6717e-02,\n",
      "           -1.2081e+00, -7.5173e-01],\n",
      "          [ 2.3400e-01, -2.9781e-01, -4.1196e-02,  ...,  2.4254e-01,\n",
      "           -6.3318e-01, -5.6717e-01],\n",
      "          ...,\n",
      "          [-1.1927e+00,  1.3182e+00,  8.4824e-01,  ..., -8.3405e-02,\n",
      "            7.9428e-01,  5.3560e-01],\n",
      "          [-1.1928e+00,  1.3186e+00,  8.5015e-01,  ..., -8.2741e-02,\n",
      "            7.8727e-01,  5.3757e-01],\n",
      "          [-1.1953e+00,  1.3226e+00,  8.5020e-01,  ..., -8.3277e-02,\n",
      "            7.9244e-01,  5.4064e-01]],\n",
      "\n",
      "         [[ 1.4329e-02,  2.1596e-02,  2.4439e-02,  ..., -6.4790e-02,\n",
      "            2.3542e-01,  4.6180e-03],\n",
      "          [-1.7783e-01, -5.5750e-01,  5.4701e-01,  ..., -7.5747e-01,\n",
      "           -1.9474e+00,  4.7546e-01],\n",
      "          [-7.1119e-01, -5.1970e-01, -3.4232e-01,  ...,  3.2235e-01,\n",
      "           -1.8866e+00, -3.1446e-01],\n",
      "          ...,\n",
      "          [-6.8206e-01,  1.0384e-01, -3.8395e-01,  ..., -8.0443e-03,\n",
      "           -6.0077e-01, -3.5249e-02],\n",
      "          [-6.7731e-01,  1.0005e-01, -3.8492e-01,  ..., -5.6424e-03,\n",
      "           -5.9313e-01, -3.4476e-02],\n",
      "          [-6.7191e-01,  1.0182e-01, -3.8526e-01,  ..., -6.1271e-03,\n",
      "           -5.8490e-01, -3.9188e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0278, -0.2285,  0.1759,  ..., -0.8720,  0.7339, -1.2083],\n",
      "          [-0.3331, -0.2673, -1.0965,  ...,  0.0762, -0.3753,  1.0802],\n",
      "          [ 0.0934,  1.1681, -1.3836,  ...,  1.8921, -0.0225,  1.3369],\n",
      "          ...,\n",
      "          [-0.9880, -0.6486,  0.0193,  ...,  0.3431,  0.5099,  0.3201],\n",
      "          [-0.9835, -0.6533,  0.0202,  ...,  0.3535,  0.5107,  0.3171],\n",
      "          [-0.9796, -0.6510,  0.0211,  ...,  0.3615,  0.5090,  0.3154]],\n",
      "\n",
      "         [[ 0.7876,  0.2094,  0.0446,  ..., -0.1404, -1.0861, -0.1898],\n",
      "          [ 0.4443, -1.7008,  2.0655,  ...,  2.3038,  4.3517,  1.6300],\n",
      "          [ 0.5408, -1.5331, -1.3338,  ..., -0.0647,  5.4304,  0.6113],\n",
      "          ...,\n",
      "          [-1.7459,  0.5101,  0.7767,  ..., -0.7929,  2.1155,  1.5502],\n",
      "          [-1.7465,  0.4964,  0.7705,  ..., -0.7983,  2.1294,  1.5561],\n",
      "          [-1.7455,  0.4857,  0.7623,  ..., -0.8012,  2.1404,  1.5687]],\n",
      "\n",
      "         [[ 0.3675, -0.3501, -0.3418,  ...,  0.3457,  1.4536,  0.2457],\n",
      "          [ 0.8278, -5.4502, -1.4256,  ..., -3.0112, -1.8108, -5.9609],\n",
      "          [-0.7058, -5.3053, -0.7869,  ..., -3.0792, -2.7161, -5.3292],\n",
      "          ...,\n",
      "          [-0.6148, -1.8784,  2.6649,  ..., -1.1187, -6.0604, -4.7648],\n",
      "          [-0.5900, -1.8812,  2.6771,  ..., -1.1212, -6.0704, -4.7827],\n",
      "          [-0.5621, -1.8802,  2.6891,  ..., -1.1210, -6.0804, -4.7956]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2211,  1.7470,  0.5167,  ...,  0.2433,  0.4647, -1.6733],\n",
      "          [ 0.7547, -5.9362,  1.2807,  ..., -2.8052, -1.8204,  4.9073],\n",
      "          [ 0.2264, -5.4596, -0.0565,  ..., -1.4788, -2.2546,  6.4607],\n",
      "          ...,\n",
      "          [ 1.2911, -5.5544, -3.0302,  ..., -1.8184, -1.1557,  4.7151],\n",
      "          [ 1.2889, -5.5647, -3.0257,  ..., -1.8207, -1.1560,  4.7257],\n",
      "          [ 1.2792, -5.5686, -3.0211,  ..., -1.8198, -1.1606,  4.7393]],\n",
      "\n",
      "         [[ 0.0437, -0.0386,  0.1539,  ..., -0.1031, -0.0938, -0.1531],\n",
      "          [-1.5399, -1.4477, -0.0901,  ..., -1.8788,  0.1700, -1.3554],\n",
      "          [ 1.5148, -0.4251,  0.2814,  ..., -0.7023, -0.2353, -0.1495],\n",
      "          ...,\n",
      "          [-0.2859, -0.7721,  0.3838,  ...,  0.1906, -0.2840, -1.4389],\n",
      "          [-0.2863, -0.7700,  0.3810,  ...,  0.1934, -0.2839, -1.4346],\n",
      "          [-0.2886, -0.7694,  0.3758,  ...,  0.1936, -0.2846, -1.4338]],\n",
      "\n",
      "         [[ 0.4139, -0.0507,  1.8796,  ..., -0.2293, -0.1941, -1.0033],\n",
      "          [ 3.9689,  2.8258, -2.5711,  ...,  1.5037,  1.1603,  2.3677],\n",
      "          [ 1.5544,  0.1039, -1.4387,  ...,  1.5024,  0.1880,  3.0890],\n",
      "          ...,\n",
      "          [-0.3637,  0.6126, -4.5734,  ..., -1.8803,  0.6299,  2.8188],\n",
      "          [-0.3756,  0.6136, -4.5963,  ..., -1.8757,  0.6405,  2.8317],\n",
      "          [-0.3902,  0.6111, -4.6128,  ..., -1.8663,  0.6419,  2.8427]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 0.0393,  0.0640, -0.0040,  ...,  0.0148,  0.1003,  0.0364],\n",
      "          [ 0.1899, -1.2731, -0.0927,  ...,  0.4180, -1.1752, -0.7597],\n",
      "          [ 0.0115, -0.0554, -0.2448,  ...,  0.5584, -1.1648, -1.5849],\n",
      "          ...,\n",
      "          [-0.2116,  0.3353, -0.1422,  ...,  0.1882,  0.0863,  0.6217],\n",
      "          [-0.2108,  0.3375, -0.1426,  ...,  0.1862,  0.0878,  0.6225],\n",
      "          [-0.2107,  0.3368, -0.1405,  ...,  0.1841,  0.0889,  0.6226]],\n",
      "\n",
      "         [[-0.0396,  0.0046,  0.0802,  ..., -0.0323, -0.0323, -0.0479],\n",
      "          [ 0.4534,  0.3375,  0.0344,  ..., -0.1345,  0.0738,  0.3358],\n",
      "          [ 0.1962,  0.1807,  0.0517,  ...,  0.3135,  0.7420, -0.2947],\n",
      "          ...,\n",
      "          [-0.7974,  0.2342, -0.1064,  ...,  0.0101, -0.6308, -0.0113],\n",
      "          [-0.7979,  0.2343, -0.1055,  ...,  0.0107, -0.6335, -0.0133],\n",
      "          [-0.7972,  0.2353, -0.1040,  ...,  0.0102, -0.6327, -0.0125]],\n",
      "\n",
      "         [[ 0.0398, -0.1029, -0.0551,  ..., -0.0279,  0.0944, -0.1543],\n",
      "          [-0.5191, -0.1946, -0.9514,  ...,  0.2838, -0.1794,  0.0183],\n",
      "          [-0.4438,  0.2204,  0.0813,  ..., -0.1464, -0.2442,  0.2359],\n",
      "          ...,\n",
      "          [-0.0948, -0.1319, -0.4499,  ...,  0.3263, -0.5335, -0.0637],\n",
      "          [-0.0920, -0.1325, -0.4462,  ...,  0.3281, -0.5305, -0.0659],\n",
      "          [-0.0895, -0.1328, -0.4468,  ...,  0.3295, -0.5299, -0.0653]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0199,  0.1196,  0.0043,  ..., -0.0280,  0.0703, -0.0397],\n",
      "          [ 0.3740, -0.5725,  0.5402,  ...,  0.3354, -0.2783,  0.1177],\n",
      "          [-0.0171, -0.4016, -0.6300,  ..., -0.4670, -0.7814,  0.4945],\n",
      "          ...,\n",
      "          [-0.1364, -0.0394, -0.2003,  ..., -0.1683, -0.0596,  0.1128],\n",
      "          [-0.1371, -0.0390, -0.1981,  ..., -0.1691, -0.0594,  0.1107],\n",
      "          [-0.1362, -0.0380, -0.1996,  ..., -0.1680, -0.0593,  0.1115]],\n",
      "\n",
      "         [[-0.1650, -0.1273, -0.0911,  ..., -0.2380, -0.0235, -0.0439],\n",
      "          [ 0.2423, -0.1982, -0.3798,  ...,  1.2084,  0.1282,  0.4970],\n",
      "          [ 0.3504, -0.8068,  0.7420,  ..., -0.5632,  0.3231, -0.3780],\n",
      "          ...,\n",
      "          [ 0.3103,  0.0732, -0.0871,  ...,  0.6661, -0.8976,  0.3399],\n",
      "          [ 0.3111,  0.0740, -0.0892,  ...,  0.6641, -0.8949,  0.3400],\n",
      "          [ 0.3092,  0.0707, -0.0869,  ...,  0.6643, -0.8929,  0.3404]],\n",
      "\n",
      "         [[ 0.1198, -0.0662, -0.0280,  ..., -0.0150, -0.0899, -0.1058],\n",
      "          [ 0.0870,  0.7072, -0.0679,  ..., -0.2282, -0.5942,  0.2226],\n",
      "          [ 0.3200,  0.3163,  0.0167,  ...,  0.3371,  0.1723, -0.0158],\n",
      "          ...,\n",
      "          [ 0.0323,  0.1847, -0.2305,  ..., -0.1628,  0.0642, -0.0316],\n",
      "          [ 0.0291,  0.1853, -0.2306,  ..., -0.1632,  0.0652, -0.0329],\n",
      "          [ 0.0281,  0.1846, -0.2324,  ..., -0.1633,  0.0645, -0.0339]]]],\n",
      "       grad_fn=<PermuteBackward0>)), (tensor([[[[-8.7030e-01, -1.3107e-01,  3.3352e-01,  ..., -9.5781e-01,\n",
      "            2.2612e-02, -2.9464e+00],\n",
      "          [ 8.7902e-01,  8.4963e-01, -2.3842e+00,  ..., -1.0832e+00,\n",
      "           -3.3621e+00,  7.3047e+00],\n",
      "          [ 2.0282e+00,  1.6204e+00, -2.7119e+00,  ..., -7.5318e-01,\n",
      "           -2.3713e+00,  8.7001e+00],\n",
      "          ...,\n",
      "          [ 2.3665e+00,  2.7176e-01, -8.0956e-01,  ...,  2.1601e-01,\n",
      "           -3.6140e-01,  8.4794e+00],\n",
      "          [ 2.3940e+00,  2.7170e-01, -8.1166e-01,  ...,  2.2065e-01,\n",
      "           -3.6102e-01,  8.4998e+00],\n",
      "          [ 2.4171e+00,  2.7640e-01, -8.1293e-01,  ...,  2.1929e-01,\n",
      "           -3.6520e-01,  8.5042e+00]],\n",
      "\n",
      "         [[ 3.9207e-01, -8.7198e-02,  4.5695e-01,  ..., -1.4772e-01,\n",
      "           -5.9226e-02, -2.2404e+00],\n",
      "          [-9.2611e-01, -1.0826e+00,  2.9565e+00,  ..., -3.3355e-01,\n",
      "            6.7193e-02,  5.2791e+00],\n",
      "          [-8.9156e-01,  4.2244e-01,  2.1734e+00,  ..., -8.6997e-01,\n",
      "           -5.6806e-01,  6.1298e+00],\n",
      "          ...,\n",
      "          [-1.5477e+00,  1.4597e+00,  7.6508e-01,  ...,  4.9372e-01,\n",
      "            4.1288e-01,  6.3367e+00],\n",
      "          [-1.5470e+00,  1.4628e+00,  7.7320e-01,  ...,  4.9164e-01,\n",
      "            4.1457e-01,  6.3613e+00],\n",
      "          [-1.5442e+00,  1.4641e+00,  7.7971e-01,  ...,  4.9161e-01,\n",
      "            4.1644e-01,  6.3742e+00]],\n",
      "\n",
      "         [[ 1.3705e-01, -6.6146e-01, -2.0491e-01,  ...,  1.4911e-01,\n",
      "            2.5535e-01, -1.7442e-01],\n",
      "          [ 9.6288e-01,  7.6793e-01,  1.0388e+00,  ...,  1.1536e+00,\n",
      "            6.9593e-01,  6.7704e-02],\n",
      "          [ 5.8754e-01,  1.6435e+00, -5.1864e-01,  ..., -8.5979e-02,\n",
      "            7.4888e-01, -7.2289e-01],\n",
      "          ...,\n",
      "          [ 8.8236e-01,  1.4320e+00,  3.9055e-01,  ..., -4.9637e-01,\n",
      "            5.9038e-01, -1.1583e+00],\n",
      "          [ 8.8082e-01,  1.4399e+00,  3.8361e-01,  ..., -4.9802e-01,\n",
      "            5.8521e-01, -1.1574e+00],\n",
      "          [ 8.7885e-01,  1.4399e+00,  3.7944e-01,  ..., -4.9391e-01,\n",
      "            5.8449e-01, -1.1566e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7748e-01,  2.7054e-02, -1.0139e-02,  ...,  1.2542e+00,\n",
      "            6.6676e-02,  1.7786e+00],\n",
      "          [ 8.4195e-01,  3.3218e-01, -3.7189e-01,  ..., -2.4526e+00,\n",
      "           -1.0317e+00, -1.7486e+00],\n",
      "          [ 8.4409e-01, -1.1855e+00,  1.1376e+00,  ..., -3.4234e+00,\n",
      "           -5.9903e-01, -1.3097e-01],\n",
      "          ...,\n",
      "          [ 7.9264e-01, -6.8713e-01, -1.6709e+00,  ..., -3.8338e+00,\n",
      "           -1.6813e+00, -2.7964e+00],\n",
      "          [ 7.9171e-01, -6.8861e-01, -1.6674e+00,  ..., -3.8575e+00,\n",
      "           -1.6882e+00, -2.8188e+00],\n",
      "          [ 7.9192e-01, -6.9283e-01, -1.6628e+00,  ..., -3.8732e+00,\n",
      "           -1.6943e+00, -2.8295e+00]],\n",
      "\n",
      "         [[-3.3143e-01, -1.4473e-01,  2.1405e-01,  ...,  2.5461e-01,\n",
      "           -2.4395e-02,  9.5473e-03],\n",
      "          [ 1.0049e+00, -3.7632e-02,  1.0678e+00,  ...,  8.0685e-01,\n",
      "            1.1032e+00, -6.8820e-01],\n",
      "          [-5.9634e-01, -1.8093e-01,  1.2563e+00,  ..., -9.6574e-01,\n",
      "            3.7069e-01,  1.5674e+00],\n",
      "          ...,\n",
      "          [-6.9411e-01, -8.7620e-01, -3.8889e-01,  ..., -8.9886e-01,\n",
      "            5.8528e-01,  2.8425e+00],\n",
      "          [-6.9949e-01, -8.7827e-01, -3.9194e-01,  ..., -8.9611e-01,\n",
      "            5.8392e-01,  2.8438e+00],\n",
      "          [-7.0207e-01, -8.7333e-01, -3.9092e-01,  ..., -8.9719e-01,\n",
      "            5.8167e-01,  2.8460e+00]],\n",
      "\n",
      "         [[ 3.4086e+00,  2.1957e+00, -2.0634e+00,  ..., -2.8445e+00,\n",
      "           -3.8668e+00, -1.2118e+00],\n",
      "          [-3.9493e+00, -9.6461e-02,  6.3140e+00,  ..., -1.6963e+00,\n",
      "            9.7586e+00,  6.5454e-01],\n",
      "          [-2.3997e+00, -2.2556e-01,  6.6139e+00,  ..., -3.4068e+00,\n",
      "            9.1602e+00, -1.0234e+00],\n",
      "          ...,\n",
      "          [-1.1648e+00, -1.4398e+00,  4.9380e+00,  ...,  4.1746e+00,\n",
      "            7.2073e+00,  5.5258e-01],\n",
      "          [-1.1894e+00, -1.4791e+00,  4.9244e+00,  ...,  4.1823e+00,\n",
      "            7.2302e+00,  5.6037e-01],\n",
      "          [-1.1933e+00, -1.5076e+00,  4.8912e+00,  ...,  4.1726e+00,\n",
      "            7.2402e+00,  5.6580e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-8.1243e-03, -4.6875e-02,  2.8140e-02,  ...,  6.3446e-02,\n",
      "            3.7524e-02,  6.2208e-02],\n",
      "          [ 3.6318e-01,  4.0679e-01, -8.8456e-01,  ..., -8.7599e-01,\n",
      "           -6.2197e-01, -2.3575e-01],\n",
      "          [-3.3992e-01, -7.2809e-01,  5.9752e-02,  ...,  7.5188e-02,\n",
      "            3.1559e-01, -8.6094e-03],\n",
      "          ...,\n",
      "          [ 1.2832e-01,  1.2119e-01,  4.7686e-01,  ..., -5.5886e-02,\n",
      "            1.0496e-01,  1.5198e-02],\n",
      "          [ 1.2808e-01,  1.2211e-01,  4.7738e-01,  ..., -5.6708e-02,\n",
      "            1.0521e-01,  1.5802e-02],\n",
      "          [ 1.2707e-01,  1.2109e-01,  4.7842e-01,  ..., -5.7654e-02,\n",
      "            1.0645e-01,  1.4842e-02]],\n",
      "\n",
      "         [[-7.9340e-02, -1.9839e-02, -1.3748e-01,  ..., -4.5362e-02,\n",
      "            4.7141e-02, -2.1514e-02],\n",
      "          [ 3.8464e-01,  4.4843e-01,  2.5690e-01,  ...,  6.0012e-02,\n",
      "           -7.9367e-01,  1.7406e-02],\n",
      "          [ 1.0737e-01,  4.0535e-01,  2.8511e-01,  ...,  1.1600e+00,\n",
      "            5.3813e-01, -4.7879e-01],\n",
      "          ...,\n",
      "          [-1.9623e-01, -3.6287e-01,  6.7860e-01,  ..., -1.0835e-01,\n",
      "           -7.0081e-02,  1.6453e-01],\n",
      "          [-1.9759e-01, -3.6236e-01,  6.7870e-01,  ..., -1.0864e-01,\n",
      "           -7.0120e-02,  1.6645e-01],\n",
      "          [-1.9833e-01, -3.6315e-01,  6.7746e-01,  ..., -1.0864e-01,\n",
      "           -6.9240e-02,  1.6740e-01]],\n",
      "\n",
      "         [[ 6.4877e-02,  1.0147e-01,  9.0731e-02,  ...,  2.4853e-02,\n",
      "           -7.0408e-02,  2.1704e-03],\n",
      "          [-2.8727e-01,  1.0639e+00, -7.6741e-01,  ..., -1.6286e-01,\n",
      "           -2.7387e-02,  2.1888e-01],\n",
      "          [ 8.6401e-02, -7.7427e-02,  2.2443e-01,  ..., -6.4616e-02,\n",
      "            1.3184e+00, -1.0460e-01],\n",
      "          ...,\n",
      "          [ 7.5205e-01,  2.2878e-01, -3.8880e-02,  ..., -1.9847e-01,\n",
      "           -1.0202e+00,  8.7670e-01],\n",
      "          [ 7.5443e-01,  2.2734e-01, -4.0151e-02,  ..., -1.9636e-01,\n",
      "           -1.0223e+00,  8.7386e-01],\n",
      "          [ 7.5262e-01,  2.2402e-01, -3.6547e-02,  ..., -1.9064e-01,\n",
      "           -1.0239e+00,  8.7529e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.9643e-04,  8.0578e-02, -8.2013e-02,  ...,  4.4803e-02,\n",
      "            3.8873e-02, -1.2982e-01],\n",
      "          [ 9.7046e-01,  7.6598e-01,  2.0733e-01,  ..., -2.7960e-02,\n",
      "            3.3511e-01,  4.8941e-01],\n",
      "          [-1.3658e+00,  8.5350e-01, -2.6189e-01,  ..., -8.0116e-01,\n",
      "           -1.5235e-01,  1.9030e-01],\n",
      "          ...,\n",
      "          [ 2.5346e-01,  2.8913e-01,  1.5425e-01,  ...,  3.8576e-01,\n",
      "            1.6846e-01, -5.3019e-01],\n",
      "          [ 2.5249e-01,  2.9045e-01,  1.5603e-01,  ...,  3.8618e-01,\n",
      "            1.6763e-01, -5.3137e-01],\n",
      "          [ 2.5227e-01,  2.8992e-01,  1.5660e-01,  ...,  3.8809e-01,\n",
      "            1.6682e-01, -5.3053e-01]],\n",
      "\n",
      "         [[-1.2790e-01, -5.0633e-02,  1.0964e-01,  ..., -7.0735e-02,\n",
      "            5.3396e-02, -2.0372e-02],\n",
      "          [-3.0156e-01, -9.6380e-01, -5.5455e-02,  ...,  3.8135e-02,\n",
      "           -1.4608e-01,  3.0372e-01],\n",
      "          [ 1.7248e+00, -9.4828e-01, -3.7490e-01,  ..., -1.2263e-01,\n",
      "            1.1158e+00, -1.7247e+00],\n",
      "          ...,\n",
      "          [-1.2478e-01,  9.1034e-01, -1.9049e-01,  ...,  3.5202e-01,\n",
      "           -1.0319e+00,  4.5953e-01],\n",
      "          [-1.2329e-01,  9.1153e-01, -1.9117e-01,  ...,  3.5062e-01,\n",
      "           -1.0346e+00,  4.5781e-01],\n",
      "          [-1.2093e-01,  9.1140e-01, -1.9078e-01,  ...,  3.5235e-01,\n",
      "           -1.0330e+00,  4.5963e-01]],\n",
      "\n",
      "         [[-1.7268e-02, -1.3456e-02, -2.0527e-02,  ..., -2.6838e-02,\n",
      "            9.7050e-03, -1.7938e-02],\n",
      "          [-7.7853e-01, -6.9514e-01,  2.7593e-02,  ...,  9.3045e-03,\n",
      "           -2.1480e-01,  2.6231e-02],\n",
      "          [ 1.8903e-01, -1.6467e-01,  2.6911e-01,  ..., -2.8697e-01,\n",
      "            1.9678e-01, -4.0040e-01],\n",
      "          ...,\n",
      "          [ 1.0922e-01,  4.4844e-01,  2.3399e-01,  ..., -1.0934e-01,\n",
      "            2.6593e-01,  3.7400e-01],\n",
      "          [ 1.1104e-01,  4.4956e-01,  2.3311e-01,  ..., -1.0910e-01,\n",
      "            2.6533e-01,  3.7501e-01],\n",
      "          [ 1.1287e-01,  4.4953e-01,  2.3299e-01,  ..., -1.1013e-01,\n",
      "            2.6425e-01,  3.7453e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.4765e-02, -2.8574e-01,  2.1615e-01,  ...,  1.6883e+00,\n",
      "           -2.1490e-01, -7.0574e-02],\n",
      "          [ 4.3964e-01,  2.0785e+00,  7.6777e-01,  ..., -4.4799e+00,\n",
      "            5.3344e-01, -9.9032e-01],\n",
      "          [-5.1704e-02,  1.9106e+00,  2.4265e-01,  ..., -3.1829e+00,\n",
      "            6.5649e-01, -1.2264e+00],\n",
      "          ...,\n",
      "          [ 8.7866e-01, -4.3152e-01,  4.7408e-02,  ..., -7.6214e-01,\n",
      "            1.6300e+00,  5.9869e-01],\n",
      "          [ 8.8122e-01, -4.3028e-01,  4.8147e-02,  ..., -7.6598e-01,\n",
      "            1.6266e+00,  6.0451e-01],\n",
      "          [ 8.8246e-01, -4.2594e-01,  4.0458e-02,  ..., -7.6504e-01,\n",
      "            1.6232e+00,  6.0140e-01]],\n",
      "\n",
      "         [[ 1.8058e-01,  9.8178e-01, -1.4240e+00,  ..., -1.2947e-01,\n",
      "            2.6640e-01,  9.1793e-01],\n",
      "          [-7.9507e-01, -5.2798e+00,  6.3241e-01,  ..., -1.5922e+00,\n",
      "            1.8192e+00, -1.4376e+00],\n",
      "          [ 2.8275e+00, -2.9457e+00,  5.4106e-01,  ..., -1.7396e-01,\n",
      "           -1.0315e-01, -1.4697e-01],\n",
      "          ...,\n",
      "          [ 3.9285e-03, -1.6406e+00,  1.0309e+00,  ...,  1.4808e-01,\n",
      "            4.4873e-01, -8.6822e-01],\n",
      "          [ 9.3346e-03, -1.6338e+00,  1.0368e+00,  ...,  1.5085e-01,\n",
      "            4.4679e-01, -8.7098e-01],\n",
      "          [ 1.5342e-02, -1.6270e+00,  1.0410e+00,  ...,  1.5332e-01,\n",
      "            4.4073e-01, -8.7037e-01]],\n",
      "\n",
      "         [[-6.6871e-01,  2.4777e-01, -4.1925e-02,  ...,  1.8080e-01,\n",
      "            4.8689e-02, -2.9203e-01],\n",
      "          [ 1.5419e+00, -1.1425e+00, -5.7651e-01,  ..., -1.4225e+00,\n",
      "           -1.7642e-01, -5.7115e-01],\n",
      "          [ 2.1565e+00, -1.1928e+00,  2.4408e-01,  ..., -5.0351e-01,\n",
      "            6.4886e-01, -3.2173e-01],\n",
      "          ...,\n",
      "          [-9.5658e-02,  1.0113e+00, -7.8253e-01,  ...,  8.0616e-02,\n",
      "            7.2207e-01, -2.0101e-01],\n",
      "          [-9.8808e-02,  1.0132e+00, -7.8311e-01,  ...,  7.7927e-02,\n",
      "            7.2227e-01, -2.0072e-01],\n",
      "          [-1.0149e-01,  1.0133e+00, -7.8733e-01,  ...,  7.7347e-02,\n",
      "            7.2131e-01, -2.0029e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0073e-02,  1.1457e-01,  1.4191e-01,  ..., -9.7227e-02,\n",
      "            2.0769e-02,  1.5848e-01],\n",
      "          [-1.8722e-01,  1.7946e-01, -5.2563e-01,  ...,  2.2158e+00,\n",
      "           -1.6230e-01, -2.3987e-01],\n",
      "          [ 1.8915e+00, -7.2676e-01,  1.0646e+00,  ...,  3.8668e-01,\n",
      "           -3.6160e-01,  2.6155e-01],\n",
      "          ...,\n",
      "          [ 2.3354e+00, -1.5393e-01,  5.1405e-01,  ...,  4.0219e-01,\n",
      "            4.2509e-01, -1.4064e-01],\n",
      "          [ 2.3421e+00, -1.5360e-01,  5.1612e-01,  ...,  3.9789e-01,\n",
      "            4.2727e-01, -1.4232e-01],\n",
      "          [ 2.3443e+00, -1.5032e-01,  5.1644e-01,  ...,  3.9363e-01,\n",
      "            4.3019e-01, -1.4534e-01]],\n",
      "\n",
      "         [[-3.0022e+00,  3.9174e-01, -1.1223e-02,  ..., -4.7967e-01,\n",
      "           -3.3196e-01,  1.2360e+00],\n",
      "          [ 5.4688e+00,  7.2843e-01, -3.0646e-01,  ..., -6.9659e-01,\n",
      "            2.0842e+00, -3.1209e-01],\n",
      "          [ 4.8602e+00,  1.3632e+00, -3.9297e-01,  ...,  4.2897e-01,\n",
      "            4.0499e-01,  4.3146e-01],\n",
      "          ...,\n",
      "          [ 3.1044e+00,  1.4018e-01,  3.3242e-01,  ..., -2.4346e+00,\n",
      "           -1.6661e+00,  1.6359e+00],\n",
      "          [ 3.1163e+00,  1.3967e-01,  3.3233e-01,  ..., -2.4367e+00,\n",
      "           -1.6679e+00,  1.6393e+00],\n",
      "          [ 3.1225e+00,  1.4099e-01,  3.3397e-01,  ..., -2.4379e+00,\n",
      "           -1.6684e+00,  1.6421e+00]],\n",
      "\n",
      "         [[-7.1128e-04, -2.4458e-01,  2.4071e-03,  ..., -1.7966e-01,\n",
      "            3.2623e-01,  7.5991e-02],\n",
      "          [ 4.7459e-01, -2.1584e+00,  5.7037e-01,  ..., -1.8233e+00,\n",
      "            1.2086e+00, -1.3540e+00],\n",
      "          [-4.7259e-01,  1.7969e-01, -2.3869e-01,  ..., -1.4658e+00,\n",
      "           -8.2617e-01, -3.0013e-02],\n",
      "          ...,\n",
      "          [ 1.0316e+00, -5.8685e-02,  8.1969e-01,  ...,  3.5984e-01,\n",
      "            9.3910e-01, -6.5611e-01],\n",
      "          [ 1.0282e+00, -5.5825e-02,  8.1790e-01,  ...,  3.5770e-01,\n",
      "            9.4056e-01, -6.5479e-01],\n",
      "          [ 1.0240e+00, -5.4611e-02,  8.1597e-01,  ...,  3.5449e-01,\n",
      "            9.3868e-01, -6.5257e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-1.6154e-02, -2.4324e-02,  4.0457e-03,  ..., -5.0684e-03,\n",
      "           -4.3276e-02,  3.5572e-01],\n",
      "          [ 2.1075e+00,  3.3239e-01,  7.0590e-01,  ..., -6.4442e-01,\n",
      "            2.0325e-01, -1.1933e+00],\n",
      "          [ 6.5785e-01,  9.5003e-01, -7.6284e-01,  ..., -1.0262e+00,\n",
      "            3.5883e-01, -1.2060e+00],\n",
      "          ...,\n",
      "          [-1.5367e-01,  1.2464e-01,  1.7819e-01,  ...,  2.3231e-01,\n",
      "            5.0881e-02,  5.1406e-01],\n",
      "          [-1.5496e-01,  1.2190e-01,  1.7693e-01,  ...,  2.2962e-01,\n",
      "            4.9577e-02,  5.1204e-01],\n",
      "          [-1.5741e-01,  1.2114e-01,  1.7641e-01,  ...,  2.2921e-01,\n",
      "            4.9361e-02,  5.1250e-01]],\n",
      "\n",
      "         [[ 2.8516e-03, -2.1652e-02,  2.0662e-02,  ..., -1.2961e-02,\n",
      "            2.0125e-02, -4.7159e-03],\n",
      "          [ 1.0375e+00, -2.5208e-01,  1.1858e+00,  ..., -1.1227e-01,\n",
      "            1.6027e+00, -5.9035e-01],\n",
      "          [ 1.8538e+00,  8.6644e-01,  1.6185e-02,  ..., -3.8412e-01,\n",
      "            1.5963e+00, -1.4000e+00],\n",
      "          ...,\n",
      "          [-6.5462e-02, -1.9355e-01, -6.0688e-01,  ...,  3.2032e-01,\n",
      "            5.2770e-01, -6.6869e-02],\n",
      "          [-6.2397e-02, -1.9417e-01, -6.0794e-01,  ...,  3.2128e-01,\n",
      "            5.2598e-01, -6.8903e-02],\n",
      "          [-5.9687e-02, -1.9406e-01, -6.0899e-01,  ...,  3.2284e-01,\n",
      "            5.2807e-01, -6.8213e-02]],\n",
      "\n",
      "         [[-5.5536e-02,  4.8930e-03, -4.0918e-02,  ..., -3.8937e-02,\n",
      "            3.6253e-04, -8.0482e-02],\n",
      "          [-1.2110e+00, -5.9457e-01, -7.2941e-01,  ..., -6.5566e-01,\n",
      "            1.4824e-01, -1.2141e+00],\n",
      "          [-1.3223e+00, -3.6461e-01, -4.5218e-02,  ...,  3.6345e-01,\n",
      "            2.9915e-01, -1.1914e-01],\n",
      "          ...,\n",
      "          [-1.3714e-01, -5.8439e-02, -1.1128e-01,  ...,  3.5583e-01,\n",
      "           -6.9597e-01, -5.3549e-01],\n",
      "          [-1.3771e-01, -6.0925e-02, -1.1334e-01,  ...,  3.5439e-01,\n",
      "           -6.9750e-01, -5.3248e-01],\n",
      "          [-1.3929e-01, -6.0765e-02, -1.1411e-01,  ...,  3.5419e-01,\n",
      "           -6.9605e-01, -5.3419e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2976e-01, -2.0310e-01, -7.0779e-02,  ..., -4.7672e-01,\n",
      "            2.2137e-01,  9.6389e-02],\n",
      "          [ 1.2666e+00, -1.3649e+00, -9.1768e-01,  ...,  3.2598e+00,\n",
      "            1.7509e-01,  4.1349e-02],\n",
      "          [ 1.8353e+00, -2.9782e-01,  1.5259e-01,  ...,  2.1286e+00,\n",
      "            4.1664e-01, -6.9614e-01],\n",
      "          ...,\n",
      "          [ 1.5599e-01, -9.2067e-02, -5.0344e-01,  ..., -4.8303e-01,\n",
      "           -3.2811e-01, -5.6448e-01],\n",
      "          [ 1.5404e-01, -9.0361e-02, -5.0294e-01,  ..., -4.8286e-01,\n",
      "           -3.2961e-01, -5.6587e-01],\n",
      "          [ 1.5710e-01, -8.7216e-02, -5.0355e-01,  ..., -4.8038e-01,\n",
      "           -3.3006e-01, -5.6525e-01]],\n",
      "\n",
      "         [[-8.1667e-02, -1.3310e-01, -4.5393e-02,  ..., -1.8094e-01,\n",
      "           -1.4460e-01,  1.1990e-01],\n",
      "          [ 1.9767e-01, -2.0686e-02,  7.5463e-03,  ..., -7.3771e-01,\n",
      "           -3.5278e-01, -1.8229e-01],\n",
      "          [-5.9571e-01,  1.7823e+00, -1.7400e+00,  ..., -1.7439e-01,\n",
      "            8.8806e-01, -1.2938e+00],\n",
      "          ...,\n",
      "          [-3.6992e-01, -5.1195e-01, -1.4463e-01,  ..., -2.6933e-01,\n",
      "            1.9371e-01,  1.2479e-01],\n",
      "          [-3.6953e-01, -5.1206e-01, -1.4677e-01,  ..., -2.7000e-01,\n",
      "            1.9141e-01,  1.2594e-01],\n",
      "          [-3.7011e-01, -5.1112e-01, -1.4789e-01,  ..., -2.7105e-01,\n",
      "            1.9076e-01,  1.2723e-01]],\n",
      "\n",
      "         [[-3.1941e-02, -3.7102e-02,  8.7104e-02,  ...,  8.3825e-02,\n",
      "           -3.5994e-02,  2.2553e-02],\n",
      "          [-6.7528e-02,  7.2829e-01, -6.5636e-01,  ..., -1.1950e+00,\n",
      "           -3.0989e-01,  5.2998e-01],\n",
      "          [-8.1797e-01,  1.3450e+00,  1.0876e+00,  ..., -1.2513e+00,\n",
      "           -3.5886e-02,  1.8242e+00],\n",
      "          ...,\n",
      "          [ 1.9757e-01,  3.6236e-01, -2.7151e-01,  ...,  5.2116e-01,\n",
      "            3.9359e-01, -2.9607e-01],\n",
      "          [ 1.9990e-01,  3.6646e-01, -2.6975e-01,  ...,  5.2354e-01,\n",
      "            3.9022e-01, -2.9403e-01],\n",
      "          [ 2.0070e-01,  3.6711e-01, -2.6816e-01,  ...,  5.2387e-01,\n",
      "            3.9074e-01, -2.9412e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.3348,  0.8583, -0.1585,  ...,  1.1293, -0.1629,  0.1378],\n",
      "          [-0.7339, -5.1293, -0.1342,  ..., -3.2350,  1.4706,  0.7144],\n",
      "          [ 1.2560, -3.2573, -0.4474,  ..., -3.5936,  0.0884,  1.0359],\n",
      "          ...,\n",
      "          [-0.5954, -3.8906,  0.6570,  ..., -3.7631,  2.0272, -1.1896],\n",
      "          [-0.5963, -3.9090,  0.6571,  ..., -3.7673,  2.0373, -1.1951],\n",
      "          [-0.5961, -3.9212,  0.6555,  ..., -3.7646,  2.0414, -1.1982]],\n",
      "\n",
      "         [[ 0.0474,  0.8748, -0.6412,  ..., -0.0219,  0.2836,  0.0141],\n",
      "          [ 0.6128,  1.2520,  1.3016,  ...,  1.1617, -1.7080, -1.0072],\n",
      "          [-2.3950,  1.1352,  0.4728,  ...,  0.2243,  0.8490, -0.7952],\n",
      "          ...,\n",
      "          [ 1.0368,  1.8419, -0.7757,  ...,  0.1975,  0.2475,  0.2217],\n",
      "          [ 1.0416,  1.8472, -0.7784,  ...,  0.1995,  0.2472,  0.2215],\n",
      "          [ 1.0445,  1.8505, -0.7800,  ...,  0.1974,  0.2469,  0.2227]],\n",
      "\n",
      "         [[-0.3118,  0.1428, -0.9919,  ..., -0.3561, -0.0489, -0.1319],\n",
      "          [-0.6023, -0.6286,  3.5674,  ..., -0.4814, -0.1837, -0.0893],\n",
      "          [-0.6349, -0.2712,  2.8809,  ...,  0.0273, -0.3463,  0.7244],\n",
      "          ...,\n",
      "          [-0.7561,  0.1470,  3.6190,  ...,  1.0701,  0.5778, -0.7804],\n",
      "          [-0.7586,  0.1474,  3.6252,  ...,  1.0691,  0.5796, -0.7809],\n",
      "          [-0.7601,  0.1477,  3.6255,  ...,  1.0676,  0.5797, -0.7841]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3822,  0.0742, -0.0555,  ..., -0.0494,  0.2271,  0.0165],\n",
      "          [-0.0731, -0.8080,  1.4979,  ..., -0.3654,  1.4223, -0.3932],\n",
      "          [-0.6035, -1.6330,  0.2038,  ..., -0.3943,  0.7946, -1.1270],\n",
      "          ...,\n",
      "          [-0.2548,  0.3794, -0.4508,  ..., -0.4943,  0.0759, -0.5417],\n",
      "          [-0.2567,  0.3820, -0.4556,  ..., -0.4924,  0.0736, -0.5408],\n",
      "          [-0.2571,  0.3839, -0.4582,  ..., -0.4912,  0.0724, -0.5374]],\n",
      "\n",
      "         [[ 0.2081,  0.0614,  0.3197,  ...,  0.4175,  0.0096,  0.2301],\n",
      "          [ 0.1414,  0.6425,  0.6252,  ..., -1.5353,  0.1810, -0.3889],\n",
      "          [ 1.9603,  0.1121,  0.7659,  ..., -1.4337, -0.7085,  0.7470],\n",
      "          ...,\n",
      "          [ 1.5525,  0.7981, -0.3841,  ...,  1.3701, -0.1813,  0.7371],\n",
      "          [ 1.5536,  0.7959, -0.3850,  ...,  1.3746, -0.1816,  0.7346],\n",
      "          [ 1.5555,  0.7960, -0.3834,  ...,  1.3769, -0.1838,  0.7347]],\n",
      "\n",
      "         [[-3.0148,  0.5458,  0.5576,  ..., -0.9447,  0.3317,  0.1998],\n",
      "          [ 7.4210,  1.1603, -2.3412,  ...,  0.7059, -0.6426,  0.9819],\n",
      "          [ 7.1873, -0.9597, -2.8083,  ...,  2.1060, -0.3500,  0.3321],\n",
      "          ...,\n",
      "          [ 8.2540,  0.3054, -0.3314,  ...,  3.8371,  0.1425,  1.4835],\n",
      "          [ 8.2766,  0.3059, -0.3246,  ...,  3.8617,  0.1478,  1.4870],\n",
      "          [ 8.2842,  0.3065, -0.3174,  ...,  3.8804,  0.1520,  1.4899]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 3.6623e-02, -5.2531e-02,  1.9742e-02,  ..., -7.7511e-02,\n",
      "            7.2721e-04, -8.8710e-02],\n",
      "          [-9.7288e-01,  9.7551e-02, -1.2793e-01,  ..., -8.6592e-01,\n",
      "            9.6055e-01,  9.4705e-01],\n",
      "          [ 1.3398e+00, -7.5667e-01,  1.7506e-03,  ..., -6.5261e-01,\n",
      "            4.0858e-01,  7.3573e-01],\n",
      "          ...,\n",
      "          [-5.6167e-01, -3.0757e-02, -5.1305e-01,  ..., -1.0568e+00,\n",
      "            6.3558e-02, -1.1500e+00],\n",
      "          [-5.6117e-01, -3.1803e-02, -5.1316e-01,  ..., -1.0554e+00,\n",
      "            6.2944e-02, -1.1528e+00],\n",
      "          [-5.5981e-01, -3.1537e-02, -5.1260e-01,  ..., -1.0541e+00,\n",
      "            6.4620e-02, -1.1542e+00]],\n",
      "\n",
      "         [[ 6.4450e-02,  2.1530e-02, -2.1496e-02,  ..., -2.4472e-02,\n",
      "            1.2992e-02, -4.4305e-03],\n",
      "          [ 2.3571e-01,  2.0766e-02, -1.3801e+00,  ...,  1.3692e+00,\n",
      "            4.9315e-01,  9.9846e-01],\n",
      "          [ 4.9820e-01, -8.3233e-01, -5.3803e-01,  ...,  5.2958e-03,\n",
      "            5.4816e-02,  4.1599e-02],\n",
      "          ...,\n",
      "          [ 5.4930e-01, -2.6463e-02,  2.0300e-02,  ..., -3.5872e-01,\n",
      "            5.5758e-01, -2.8946e-01],\n",
      "          [ 5.4826e-01, -2.5998e-02,  2.1444e-02,  ..., -3.6002e-01,\n",
      "            5.5629e-01, -2.8931e-01],\n",
      "          [ 5.4458e-01, -2.5153e-02,  2.1765e-02,  ..., -3.6054e-01,\n",
      "            5.5685e-01, -2.8899e-01]],\n",
      "\n",
      "         [[ 7.8684e-02,  1.9472e-02,  6.3902e-03,  ...,  1.7769e-02,\n",
      "           -6.6467e-02, -6.4331e-02],\n",
      "          [ 6.6447e-01,  1.5695e-01, -3.0897e-01,  ..., -2.5934e-02,\n",
      "            7.7876e-02,  7.9969e-01],\n",
      "          [-3.7823e-01,  1.0106e-01,  4.8544e-01,  ...,  1.6755e+00,\n",
      "            1.0622e+00,  8.2720e-01],\n",
      "          ...,\n",
      "          [-4.2397e-01,  1.3036e+00, -2.2317e-01,  ..., -1.3668e-01,\n",
      "            2.2345e+00,  1.5424e+00],\n",
      "          [-4.2337e-01,  1.3050e+00, -2.2904e-01,  ..., -1.3808e-01,\n",
      "            2.2336e+00,  1.5432e+00],\n",
      "          [-4.2393e-01,  1.3066e+00, -2.3213e-01,  ..., -1.3614e-01,\n",
      "            2.2390e+00,  1.5425e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.2002e-03,  2.2984e-02,  2.6918e-02,  ..., -8.5574e-02,\n",
      "           -2.0333e-02,  2.4534e-02],\n",
      "          [-6.2101e-01, -3.4178e-01, -2.3836e-01,  ...,  1.5253e+00,\n",
      "           -5.2830e-01,  6.2624e-01],\n",
      "          [ 1.0397e-02, -1.2514e+00, -1.8947e-01,  ..., -3.8586e-01,\n",
      "           -1.1394e+00, -1.2173e+00],\n",
      "          ...,\n",
      "          [ 3.1288e-01,  5.4705e-01,  6.2838e-01,  ...,  2.7826e-01,\n",
      "            1.7716e-01,  1.5350e-01],\n",
      "          [ 3.1409e-01,  5.4709e-01,  6.3037e-01,  ...,  2.7600e-01,\n",
      "            1.7397e-01,  1.5507e-01],\n",
      "          [ 3.1506e-01,  5.4618e-01,  6.3090e-01,  ...,  2.7390e-01,\n",
      "            1.7191e-01,  1.5527e-01]],\n",
      "\n",
      "         [[ 3.6519e-02, -1.5498e-02,  2.4342e-02,  ...,  3.0825e-02,\n",
      "           -7.8301e-03, -2.5399e-03],\n",
      "          [ 2.1976e-02,  5.4030e-01, -1.2397e+00,  ..., -5.6328e-02,\n",
      "            8.2131e-01, -8.4140e-01],\n",
      "          [-1.1278e-01,  7.5571e-01,  1.5123e-01,  ...,  1.4032e+00,\n",
      "            5.5952e-01,  1.3037e-01],\n",
      "          ...,\n",
      "          [ 3.2119e-01, -4.7496e-01, -8.6996e-01,  ...,  1.0213e-01,\n",
      "            7.0307e-01, -5.2851e-01],\n",
      "          [ 3.1873e-01, -4.7516e-01, -8.6986e-01,  ...,  1.0244e-01,\n",
      "            7.0105e-01, -5.2963e-01],\n",
      "          [ 3.1815e-01, -4.7340e-01, -8.7016e-01,  ...,  1.0243e-01,\n",
      "            6.9946e-01, -5.3005e-01]],\n",
      "\n",
      "         [[ 7.5280e-02, -1.9492e-01, -7.6429e-02,  ..., -1.8599e-02,\n",
      "            1.9642e-01, -4.4872e-02],\n",
      "          [-5.2066e-01, -4.2676e-01, -1.4494e+00,  ...,  5.5262e-02,\n",
      "           -7.3229e-01,  3.5040e-01],\n",
      "          [ 2.2825e-01,  8.2742e-01, -1.2306e+00,  ..., -8.5409e-01,\n",
      "           -2.7409e-01,  3.4722e-02],\n",
      "          ...,\n",
      "          [-6.3150e-01, -5.6252e-01, -7.5811e-01,  ..., -3.7442e-01,\n",
      "           -1.9799e-01, -1.9095e-01],\n",
      "          [-6.3268e-01, -5.6360e-01, -7.5779e-01,  ..., -3.7447e-01,\n",
      "           -1.9919e-01, -1.9060e-01],\n",
      "          [-6.3335e-01, -5.6423e-01, -7.5932e-01,  ..., -3.7470e-01,\n",
      "           -1.9876e-01, -1.9099e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0622, -0.2432, -0.1308,  ...,  0.6292,  0.7119, -0.2988],\n",
      "          [-3.5855, -2.5353,  0.7704,  ...,  0.8290, -5.8206,  0.8902],\n",
      "          [-3.2549, -1.3895,  0.7481,  ...,  0.7191, -4.9562,  0.5828],\n",
      "          ...,\n",
      "          [-4.9740, -0.9649, -1.1593,  ..., -0.3091, -4.4203,  0.0742],\n",
      "          [-4.9941, -0.9588, -1.1587,  ..., -0.3212, -4.4315,  0.0714],\n",
      "          [-5.0058, -0.9509, -1.1579,  ..., -0.3280, -4.4391,  0.0690]],\n",
      "\n",
      "         [[-0.1469, -0.0684,  0.1629,  ..., -0.0474, -0.8726, -0.2045],\n",
      "          [ 0.1480, -0.2014, -0.4688,  ..., -0.0923, -0.2896, -1.5943],\n",
      "          [ 0.8050, -0.6575,  0.0987,  ..., -0.2922, -0.8078,  0.6484],\n",
      "          ...,\n",
      "          [ 0.9374,  0.2568,  0.1483,  ..., -1.0484, -1.7095, -0.3753],\n",
      "          [ 0.9373,  0.2587,  0.1484,  ..., -1.0460, -1.7080, -0.3777],\n",
      "          [ 0.9341,  0.2569,  0.1460,  ..., -1.0440, -1.7074, -0.3792]],\n",
      "\n",
      "         [[ 0.1925,  0.2996,  1.1201,  ..., -0.4592,  0.4389, -0.5034],\n",
      "          [-1.1269, -1.0395, -2.0093,  ..., -1.8079, -1.2817, -0.1274],\n",
      "          [-0.6999, -1.2418, -1.3357,  ..., -0.7783, -1.8813,  2.7335],\n",
      "          ...,\n",
      "          [ 0.0403,  0.5639, -0.3796,  ..., -1.0196, -0.2296,  1.5722],\n",
      "          [ 0.0413,  0.5696, -0.3872,  ..., -1.0190, -0.2275,  1.5720],\n",
      "          [ 0.0361,  0.5736, -0.3917,  ..., -1.0187, -0.2227,  1.5742]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1420,  0.0799, -0.2224,  ...,  0.0068,  0.1565,  0.0186],\n",
      "          [-2.2436, -0.3818, -1.8959,  ...,  1.4808, -1.6620, -1.2042],\n",
      "          [-2.2202, -0.2189, -0.1208,  ..., -0.1441,  1.0976, -0.7384],\n",
      "          ...,\n",
      "          [-1.1799,  0.7541,  0.6015,  ..., -0.8486, -0.9950,  0.5253],\n",
      "          [-1.1839,  0.7562,  0.6015,  ..., -0.8533, -0.9956,  0.5271],\n",
      "          [-1.1873,  0.7564,  0.5996,  ..., -0.8579, -0.9957,  0.5299]],\n",
      "\n",
      "         [[-0.3561, -2.1814,  0.1236,  ..., -0.0884, -0.0492,  0.9104],\n",
      "          [ 1.0831,  3.0001,  0.0141,  ..., -0.6536,  0.2618, -1.4213],\n",
      "          [ 0.2892,  2.3227,  0.6136,  ...,  0.0881, -1.4134,  0.4447],\n",
      "          ...,\n",
      "          [-0.3564, -0.9742,  0.2959,  ...,  0.5829, -0.8530,  1.6845],\n",
      "          [-0.3503, -0.9698,  0.2995,  ...,  0.5826, -0.8513,  1.6901],\n",
      "          [-0.3487, -0.9688,  0.2990,  ...,  0.5828, -0.8502,  1.6945]],\n",
      "\n",
      "         [[ 0.3734,  0.0663, -0.1479,  ...,  0.6412,  0.1363,  0.2640],\n",
      "          [-0.9330, -1.3735, -0.6337,  ..., -1.2171,  1.0816, -1.2383],\n",
      "          [ 0.2770,  0.0913,  0.0168,  ..., -0.0263, -0.3775, -0.5661],\n",
      "          ...,\n",
      "          [ 1.0270,  0.1557, -0.7223,  ...,  0.7892,  0.6039, -1.6302],\n",
      "          [ 1.0275,  0.1601, -0.7259,  ...,  0.7919,  0.6043, -1.6306],\n",
      "          [ 1.0287,  0.1629, -0.7272,  ...,  0.7937,  0.6068, -1.6294]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[-3.4548e-02,  5.3397e-02, -6.4730e-02,  ..., -2.3077e-02,\n",
      "            5.7554e-05,  2.0528e-02],\n",
      "          [ 1.6396e+00, -4.8811e-01, -9.9508e-03,  ...,  1.7677e-01,\n",
      "           -4.7795e-01, -1.0079e+00],\n",
      "          [-4.7230e-02, -5.4193e-01, -6.6728e-01,  ...,  2.6631e-01,\n",
      "           -6.5821e-01, -2.3162e-01],\n",
      "          ...,\n",
      "          [ 4.7748e-01,  3.8792e-01,  3.7320e-02,  ..., -2.8887e-02,\n",
      "            1.0704e-04, -1.5785e-01],\n",
      "          [ 4.7674e-01,  3.8816e-01,  3.7603e-02,  ..., -2.9401e-02,\n",
      "            8.9750e-04, -1.5868e-01],\n",
      "          [ 4.7709e-01,  3.8760e-01,  3.8057e-02,  ..., -3.0172e-02,\n",
      "            8.9440e-04, -1.5769e-01]],\n",
      "\n",
      "         [[ 1.1421e-02, -2.3286e-02,  2.4031e-02,  ...,  1.9458e-02,\n",
      "           -5.3156e-02,  1.4023e-02],\n",
      "          [-3.8006e-01, -9.7725e-01, -1.2923e+00,  ...,  7.0721e-01,\n",
      "            3.2788e-01, -4.0794e-01],\n",
      "          [-3.0023e-01, -6.3127e-03, -1.3531e+00,  ...,  1.6603e-01,\n",
      "            6.2102e-01,  5.8035e-01],\n",
      "          ...,\n",
      "          [ 1.8681e-01, -1.5142e-01,  2.1515e-01,  ...,  1.8025e-01,\n",
      "           -4.0431e-01, -2.8227e-01],\n",
      "          [ 1.8554e-01, -1.5147e-01,  2.1539e-01,  ...,  1.7901e-01,\n",
      "           -4.0512e-01, -2.8342e-01],\n",
      "          [ 1.8666e-01, -1.5169e-01,  2.1365e-01,  ...,  1.7874e-01,\n",
      "           -4.0700e-01, -2.8376e-01]],\n",
      "\n",
      "         [[ 4.1737e-02, -2.4639e-02,  5.5960e-02,  ...,  2.9685e-02,\n",
      "           -5.1146e-03, -2.1417e-03],\n",
      "          [-3.6082e-01,  1.1219e+00,  2.5839e-01,  ..., -1.1847e+00,\n",
      "            4.4165e-01, -3.9130e-01],\n",
      "          [-8.4110e-01, -1.5485e-01, -7.7197e-01,  ..., -5.8200e-01,\n",
      "            2.1174e+00, -4.3486e-01],\n",
      "          ...,\n",
      "          [ 5.1644e-03,  1.3224e-01, -1.5668e-01,  ..., -2.3310e-01,\n",
      "           -1.8959e-01,  2.3242e-03],\n",
      "          [ 2.9029e-03,  1.3392e-01, -1.5507e-01,  ..., -2.3243e-01,\n",
      "           -1.9028e-01,  2.3448e-03],\n",
      "          [ 2.3367e-03,  1.3402e-01, -1.5552e-01,  ..., -2.3416e-01,\n",
      "           -1.9163e-01, -2.1503e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8734e-01,  7.9658e-02,  5.4667e-02,  ...,  4.3881e-02,\n",
      "            4.9607e-02, -1.2179e-01],\n",
      "          [-2.4291e-01, -2.3118e-01, -1.4433e-01,  ..., -2.6102e-01,\n",
      "            8.7648e-01,  1.4179e+00],\n",
      "          [ 1.0404e-01,  1.0573e+00,  9.7879e-01,  ..., -2.0618e-01,\n",
      "            6.0192e-01,  8.3876e-01],\n",
      "          ...,\n",
      "          [-1.0232e+00,  1.6702e-01,  8.9921e-01,  ...,  9.7783e-02,\n",
      "            1.1119e+00, -4.7999e-01],\n",
      "          [-1.0233e+00,  1.6519e-01,  9.0218e-01,  ...,  9.8738e-02,\n",
      "            1.1117e+00, -4.7897e-01],\n",
      "          [-1.0244e+00,  1.6532e-01,  9.0320e-01,  ...,  9.8967e-02,\n",
      "            1.1107e+00, -4.7763e-01]],\n",
      "\n",
      "         [[-5.9185e-01, -1.7369e-05,  4.2870e-02,  ..., -1.6821e-02,\n",
      "            1.4827e-02, -6.8937e-03],\n",
      "          [-1.4579e+00, -1.5723e-01, -5.7404e-01,  ..., -1.8376e-01,\n",
      "            9.4737e-01,  4.8910e-01],\n",
      "          [-1.4394e+00, -2.8523e-01, -1.1037e-01,  ..., -3.1080e-01,\n",
      "            7.8038e-01,  8.8324e-01],\n",
      "          ...,\n",
      "          [-7.6288e-01, -4.7627e-01, -1.6473e-01,  ...,  9.6439e-02,\n",
      "            4.1311e-01, -2.9448e-01],\n",
      "          [-7.6479e-01, -4.7628e-01, -1.6366e-01,  ...,  9.6300e-02,\n",
      "            4.1357e-01, -2.9332e-01],\n",
      "          [-7.6726e-01, -4.7838e-01, -1.6351e-01,  ...,  9.5530e-02,\n",
      "            4.1335e-01, -2.9444e-01]],\n",
      "\n",
      "         [[-2.5289e-03,  8.2326e-02, -4.4995e-02,  ...,  5.7166e-02,\n",
      "            3.3987e-02, -4.4381e-02],\n",
      "          [-1.8215e+00,  6.7447e-01,  1.4626e-01,  ..., -2.0834e-01,\n",
      "           -6.8011e-01, -9.1081e-02],\n",
      "          [-4.2193e-01, -5.5222e-01, -1.0669e+00,  ...,  3.3618e-01,\n",
      "           -2.7262e-01, -6.6286e-01],\n",
      "          ...,\n",
      "          [ 2.3794e-02,  1.6799e-02,  2.5984e-01,  ..., -2.9553e-01,\n",
      "           -1.0909e-02,  2.0214e-01],\n",
      "          [ 2.3292e-02,  1.5948e-02,  2.5920e-01,  ..., -2.9362e-01,\n",
      "           -1.2203e-02,  2.0021e-01],\n",
      "          [ 2.4077e-02,  1.5322e-02,  2.5923e-01,  ..., -2.9178e-01,\n",
      "           -1.3544e-02,  1.9907e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0372, -2.3316,  0.1670,  ..., -0.2257, -0.1957,  0.0710],\n",
      "          [-1.1617,  5.7819,  0.4649,  ...,  0.8789, -0.4382,  0.4594],\n",
      "          [ 0.0643,  4.0479, -0.6301,  ..., -0.1950, -1.9553,  0.0638],\n",
      "          ...,\n",
      "          [-1.0440,  1.3966,  0.4239,  ..., -0.2785, -1.1959,  0.9008],\n",
      "          [-1.0451,  1.4018,  0.4257,  ..., -0.2752, -1.1939,  0.9002],\n",
      "          [-1.0416,  1.4018,  0.4254,  ..., -0.2762, -1.1921,  0.9007]],\n",
      "\n",
      "         [[-0.7982,  0.2271,  0.4667,  ..., -0.5218,  1.0731,  1.1169],\n",
      "          [ 0.6056,  0.5853,  0.7010,  ..., -0.0171,  1.8413, -2.3594],\n",
      "          [ 0.9425,  0.0762,  1.6165,  ...,  0.5875,  1.2897, -0.7812],\n",
      "          ...,\n",
      "          [-0.0664, -0.9769,  1.1689,  ..., -1.0722,  1.8201,  0.9656],\n",
      "          [-0.0660, -0.9779,  1.1688,  ..., -1.0735,  1.8219,  0.9707],\n",
      "          [-0.0676, -0.9788,  1.1685,  ..., -1.0737,  1.8203,  0.9743]],\n",
      "\n",
      "         [[-0.8517,  0.4646,  0.0205,  ...,  0.4969, -0.2337,  1.1502],\n",
      "          [ 0.4491, -2.2600, -0.1684,  ..., -0.7217,  0.4886,  0.7755],\n",
      "          [ 2.0659, -0.7061,  0.0094,  ...,  0.7886,  0.8079, -0.6632],\n",
      "          ...,\n",
      "          [-0.3551, -0.1579,  1.1106,  ...,  0.4754, -0.1837, -0.4140],\n",
      "          [-0.3545, -0.1567,  1.1107,  ...,  0.4759, -0.1848, -0.4161],\n",
      "          [-0.3545, -0.1571,  1.1112,  ...,  0.4769, -0.1870, -0.4172]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3062, -0.1479,  0.1367,  ...,  0.1887,  1.7284, -2.8581],\n",
      "          [-0.3847, -2.4209, -2.0211,  ..., -0.0423, -5.5258,  6.0159],\n",
      "          [-0.4528, -0.4905,  0.0476,  ..., -1.2795, -2.5008,  3.9053],\n",
      "          ...,\n",
      "          [-0.7489,  0.5960,  0.1993,  ...,  1.0017, -2.0469,  3.0264],\n",
      "          [-0.7494,  0.5966,  0.1992,  ...,  1.0019, -2.0514,  3.0359],\n",
      "          [-0.7505,  0.5955,  0.2006,  ...,  1.0010, -2.0499,  3.0375]],\n",
      "\n",
      "         [[ 0.1831,  0.3681,  0.2261,  ..., -0.2125,  0.0277, -0.1478],\n",
      "          [-1.0061,  0.1369, -0.7097,  ...,  1.4483,  0.3864,  0.1570],\n",
      "          [-1.2585, -0.5253, -1.0317,  ...,  0.7033,  0.3829,  0.5597],\n",
      "          ...,\n",
      "          [ 0.6686,  0.8018,  0.0336,  ..., -0.5684, -0.8865,  0.7518],\n",
      "          [ 0.6723,  0.8031,  0.0350,  ..., -0.5720, -0.8887,  0.7518],\n",
      "          [ 0.6732,  0.8043,  0.0363,  ..., -0.5753, -0.8891,  0.7495]],\n",
      "\n",
      "         [[ 0.3660,  0.1106,  0.6124,  ...,  0.5269,  0.5722, -0.3355],\n",
      "          [-0.6914, -1.7580, -1.0766,  ..., -0.9414, -3.9056,  0.5220],\n",
      "          [ 1.5443, -0.2836, -0.5388,  ..., -0.6562, -2.8907, -0.6476],\n",
      "          ...,\n",
      "          [ 0.6686,  1.2162,  0.6427,  ..., -1.4200, -2.4031, -0.5370],\n",
      "          [ 0.6679,  1.2172,  0.6474,  ..., -1.4236, -2.4089, -0.5377],\n",
      "          [ 0.6669,  1.2186,  0.6515,  ..., -1.4221, -2.4097, -0.5399]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 5.4477e-02, -1.0079e-02, -7.1999e-03,  ...,  1.2584e-01,\n",
      "           -6.7116e-02, -3.4897e-02],\n",
      "          [-1.3886e+00,  1.2505e-01,  1.5337e+00,  ...,  2.8176e-02,\n",
      "            1.3031e+00,  8.0599e-01],\n",
      "          [-1.3729e+00,  3.7036e-01, -3.0922e-01,  ..., -7.7045e-01,\n",
      "           -2.8802e-01,  1.2563e+00],\n",
      "          ...,\n",
      "          [ 8.2083e-02,  3.0486e-01,  3.9830e-01,  ..., -3.3133e-02,\n",
      "           -1.5220e-01, -2.6761e-01],\n",
      "          [ 8.5044e-02,  3.0629e-01,  3.9798e-01,  ..., -3.1128e-02,\n",
      "           -1.5295e-01, -2.6728e-01],\n",
      "          [ 8.5668e-02,  3.0577e-01,  3.9666e-01,  ..., -3.0529e-02,\n",
      "           -1.5432e-01, -2.6863e-01]],\n",
      "\n",
      "         [[-6.2819e-04,  3.5647e-02,  4.8210e-02,  ..., -7.1052e-03,\n",
      "           -7.6824e-03,  1.6442e-03],\n",
      "          [-6.4987e-01, -7.6724e-01,  9.8571e-01,  ..., -1.4795e+00,\n",
      "           -9.2898e-01, -9.5714e-01],\n",
      "          [-1.2847e+00,  1.8249e+00, -2.0985e-01,  ...,  1.3219e+00,\n",
      "            4.5536e-02, -6.0319e-01],\n",
      "          ...,\n",
      "          [ 9.2815e-02, -1.9917e-01,  3.6635e-01,  ...,  3.3523e-03,\n",
      "           -1.9260e-01,  1.8215e-01],\n",
      "          [ 9.2814e-02, -1.9811e-01,  3.6702e-01,  ...,  4.5360e-03,\n",
      "           -1.9111e-01,  1.8296e-01],\n",
      "          [ 9.4647e-02, -1.9732e-01,  3.6850e-01,  ...,  5.2175e-03,\n",
      "           -1.9185e-01,  1.8382e-01]],\n",
      "\n",
      "         [[ 5.2694e-02, -4.0038e-02,  6.1282e-02,  ...,  4.4517e-02,\n",
      "           -6.2781e-02, -6.8190e-02],\n",
      "          [-4.9701e-01, -1.0709e-01,  4.2327e-01,  ...,  2.6530e-01,\n",
      "            1.9708e-01,  9.3207e-01],\n",
      "          [-1.4602e+00,  5.2243e-01,  8.5440e-01,  ..., -1.6220e-02,\n",
      "           -5.5025e-01, -7.1879e-01],\n",
      "          ...,\n",
      "          [-1.5705e-01, -1.9575e-01, -8.9165e-02,  ..., -2.9045e-01,\n",
      "           -2.0415e-01,  1.9777e-02],\n",
      "          [-1.5661e-01, -1.9689e-01, -9.0179e-02,  ..., -2.9092e-01,\n",
      "           -2.0552e-01,  2.1589e-02],\n",
      "          [-1.5502e-01, -1.9632e-01, -9.1271e-02,  ..., -2.9110e-01,\n",
      "           -2.0779e-01,  2.2289e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.5199e-02, -4.4339e-02,  4.9220e-02,  ..., -8.3539e-02,\n",
      "            5.0388e-02,  7.1123e-03],\n",
      "          [-1.0189e-01, -8.8846e-01,  2.4153e+00,  ..., -4.0559e-02,\n",
      "            1.2145e+00, -5.5087e-01],\n",
      "          [-7.0552e-01,  9.6448e-01, -1.1062e-01,  ..., -3.7599e-01,\n",
      "            1.0998e-01,  6.0777e-02],\n",
      "          ...,\n",
      "          [ 2.8862e-01, -3.4132e-02,  4.3107e-01,  ..., -8.0387e-01,\n",
      "            2.5655e-01,  5.0889e-02],\n",
      "          [ 2.8916e-01, -3.4520e-02,  4.3015e-01,  ..., -8.0391e-01,\n",
      "            2.5687e-01,  5.1432e-02],\n",
      "          [ 2.8918e-01, -3.5930e-02,  4.2865e-01,  ..., -8.0232e-01,\n",
      "            2.5750e-01,  5.2097e-02]],\n",
      "\n",
      "         [[ 1.3284e-01, -7.5168e-02,  1.2040e-01,  ...,  5.7789e-02,\n",
      "            2.8678e-02, -1.3395e-01],\n",
      "          [-1.6283e+00,  2.6347e-01, -5.2707e-01,  ...,  7.6810e-02,\n",
      "            5.4005e-01,  2.7727e-02],\n",
      "          [-1.8772e+00,  2.3652e+00,  2.9592e-01,  ..., -1.4481e+00,\n",
      "           -3.0623e+00,  1.2836e+00],\n",
      "          ...,\n",
      "          [-6.6010e-02, -7.7975e-02,  1.2157e+00,  ..., -7.5871e-01,\n",
      "            5.5496e-01,  3.7478e-02],\n",
      "          [-6.6141e-02, -7.8380e-02,  1.2148e+00,  ..., -7.6114e-01,\n",
      "            5.5358e-01,  3.8058e-02],\n",
      "          [-6.5352e-02, -7.9375e-02,  1.2152e+00,  ..., -7.6221e-01,\n",
      "            5.5367e-01,  3.9483e-02]],\n",
      "\n",
      "         [[ 2.1119e-01, -4.4821e-02, -5.3789e-02,  ...,  4.3649e-02,\n",
      "            5.0222e-02,  2.0442e-02],\n",
      "          [-3.4639e-01, -1.1319e+00,  3.8547e-01,  ...,  6.3525e-03,\n",
      "           -9.0637e-01,  9.0627e-02],\n",
      "          [-1.0463e+00, -1.2085e+00, -2.8679e-01,  ..., -1.1050e+00,\n",
      "           -1.2092e+00, -1.2036e+00],\n",
      "          ...,\n",
      "          [ 2.8213e-02,  1.5234e+00, -1.5652e-01,  ..., -1.3059e-01,\n",
      "            2.5411e-01,  5.3168e-01],\n",
      "          [ 2.7647e-02,  1.5256e+00, -1.5665e-01,  ..., -1.3303e-01,\n",
      "            2.5585e-01,  5.3030e-01],\n",
      "          [ 2.9102e-02,  1.5245e+00, -1.5698e-01,  ..., -1.3078e-01,\n",
      "            2.5654e-01,  5.3038e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.0048e-02, -2.4519e-01, -4.4249e-01,  ...,  3.2120e-01,\n",
      "            3.1733e-01,  3.7760e-01],\n",
      "          [-4.7956e-01,  2.0112e-01, -6.2867e-01,  ...,  1.5845e+00,\n",
      "           -7.7267e-01, -1.5101e+00],\n",
      "          [ 1.7934e+00, -7.8195e-01, -2.0895e+00,  ...,  1.6963e-01,\n",
      "            1.8722e-01,  1.1767e+00],\n",
      "          ...,\n",
      "          [-3.0427e-01, -3.9578e-01, -5.2132e-01,  ..., -2.3989e+00,\n",
      "            2.0898e-01,  1.9537e+00],\n",
      "          [-3.0569e-01, -3.9624e-01, -5.2127e-01,  ..., -2.4047e+00,\n",
      "            2.0638e-01,  1.9568e+00],\n",
      "          [-3.0668e-01, -3.9528e-01, -5.2222e-01,  ..., -2.4089e+00,\n",
      "            2.0464e-01,  1.9582e+00]],\n",
      "\n",
      "         [[-2.8365e-01,  1.6541e-01,  1.1532e-01,  ...,  4.8897e-02,\n",
      "           -1.1488e+00, -1.5094e-01],\n",
      "          [ 4.8387e-01, -1.4985e+00, -3.7533e-01,  ...,  9.8088e-01,\n",
      "            4.3544e-02, -2.4499e-01],\n",
      "          [-2.0918e-01, -4.9754e-01, -1.9810e-01,  ...,  1.0663e+00,\n",
      "           -1.0872e+00,  2.6840e+00],\n",
      "          ...,\n",
      "          [-4.2254e-01,  4.7095e-01, -1.2082e+00,  ...,  1.8118e+00,\n",
      "           -4.6410e-02, -4.6662e-01],\n",
      "          [-4.2397e-01,  4.7149e-01, -1.2103e+00,  ...,  1.8131e+00,\n",
      "           -4.8266e-02, -4.6622e-01],\n",
      "          [-4.2480e-01,  4.7262e-01, -1.2105e+00,  ...,  1.8121e+00,\n",
      "           -5.0284e-02, -4.6680e-01]],\n",
      "\n",
      "         [[-1.2461e+00, -1.0842e-01,  5.5454e-01,  ..., -6.5962e-01,\n",
      "            4.7463e-01, -2.7957e-01],\n",
      "          [ 1.2219e+00, -1.3562e-02, -1.8268e-01,  ..., -1.0927e-01,\n",
      "            6.8062e-01, -3.8454e-01],\n",
      "          [ 1.4051e+00,  5.4274e-01,  1.4058e-01,  ...,  7.9600e-02,\n",
      "            3.7225e-01,  2.2546e+00],\n",
      "          ...,\n",
      "          [-2.0745e-01,  2.0968e+00,  6.5062e-01,  ..., -2.4018e-01,\n",
      "            9.5491e-01,  3.0196e+00],\n",
      "          [-2.0792e-01,  2.0993e+00,  6.4829e-01,  ..., -2.4122e-01,\n",
      "            9.5425e-01,  3.0246e+00],\n",
      "          [-2.0991e-01,  2.0990e+00,  6.4756e-01,  ..., -2.4249e-01,\n",
      "            9.5205e-01,  3.0269e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8925e-01, -9.1099e-01, -3.9517e-01,  ..., -1.0467e+00,\n",
      "           -4.1457e-01,  4.9478e-01],\n",
      "          [ 1.1100e+00, -1.0900e+00, -1.2293e+00,  ...,  2.4608e-02,\n",
      "            1.3240e+00, -9.5905e-01],\n",
      "          [ 1.2287e+00, -1.1757e+00, -1.6570e+00,  ...,  7.9816e-01,\n",
      "           -9.2805e-01, -1.6167e+00],\n",
      "          ...,\n",
      "          [ 7.1493e-01, -1.6842e+00, -6.2766e-01,  ..., -1.3197e+00,\n",
      "           -1.6775e+00, -1.5459e+00],\n",
      "          [ 7.1188e-01, -1.6891e+00, -6.2651e-01,  ..., -1.3212e+00,\n",
      "           -1.6799e+00, -1.5482e+00],\n",
      "          [ 7.0998e-01, -1.6937e+00, -6.2803e-01,  ..., -1.3207e+00,\n",
      "           -1.6798e+00, -1.5497e+00]],\n",
      "\n",
      "         [[-9.1097e-01,  2.5492e+00,  3.2162e-01,  ...,  3.5468e-01,\n",
      "            1.9495e+00, -5.2428e-01],\n",
      "          [-6.1873e-04, -4.8603e+00, -6.1536e-02,  ...,  8.3504e-01,\n",
      "           -3.5077e+00,  2.9900e+00],\n",
      "          [ 2.4218e-02, -2.9186e+00,  1.1873e+00,  ..., -6.7542e-01,\n",
      "           -2.8338e+00,  1.4088e+00],\n",
      "          ...,\n",
      "          [-7.9881e-01, -2.6615e+00,  6.5113e-01,  ...,  9.9575e-01,\n",
      "           -3.9190e+00, -9.6910e-01],\n",
      "          [-8.0192e-01, -2.6653e+00,  6.4752e-01,  ...,  9.9864e-01,\n",
      "           -3.9325e+00, -9.6991e-01],\n",
      "          [-8.0436e-01, -2.6616e+00,  6.4415e-01,  ...,  1.0015e+00,\n",
      "           -3.9372e+00, -9.6999e-01]],\n",
      "\n",
      "         [[-2.0122e+00, -3.6750e-01, -1.1128e+00,  ..., -3.8888e-01,\n",
      "            5.8251e-02,  2.5243e-01],\n",
      "          [ 3.7357e+00,  4.8626e-01,  2.6720e+00,  ...,  2.7053e-01,\n",
      "            9.4404e-01,  1.5985e+00],\n",
      "          [ 1.6792e+00, -5.0366e-01,  1.1007e+00,  ..., -6.9718e-01,\n",
      "           -2.5605e-01,  4.0844e-01],\n",
      "          ...,\n",
      "          [-2.9859e-01,  1.1224e-02,  6.9480e-01,  ...,  6.7964e-01,\n",
      "           -3.9114e-01, -2.2775e-01],\n",
      "          [-2.9470e-01,  1.1516e-02,  6.9621e-01,  ...,  6.8058e-01,\n",
      "           -3.9047e-01, -2.2888e-01],\n",
      "          [-2.9456e-01,  1.0515e-02,  6.9378e-01,  ...,  6.8118e-01,\n",
      "           -3.9021e-01, -2.3002e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-5.5811e-02, -8.1161e-02,  3.5665e-02,  ...,  1.0902e-01,\n",
      "           -2.7879e-02,  2.5281e-02],\n",
      "          [-9.0960e-01, -3.8608e-01,  1.2446e-01,  ...,  3.0909e-01,\n",
      "            1.1499e+00,  3.5506e-01],\n",
      "          [-1.3061e+00, -3.7714e-01, -1.0021e+00,  ..., -7.1394e-01,\n",
      "            8.5181e-01, -5.1080e-01],\n",
      "          ...,\n",
      "          [ 3.5443e-02, -2.0478e-01,  1.3950e-02,  ...,  2.0006e-01,\n",
      "           -6.7329e-02,  4.1474e-01],\n",
      "          [ 3.4707e-02, -2.0593e-01,  1.3102e-02,  ...,  2.0037e-01,\n",
      "           -6.8776e-02,  4.1459e-01],\n",
      "          [ 3.4532e-02, -2.0515e-01,  1.3776e-02,  ...,  2.0068e-01,\n",
      "           -6.8435e-02,  4.1395e-01]],\n",
      "\n",
      "         [[ 1.6063e-02,  7.9706e-03, -3.7657e-02,  ...,  2.3601e-02,\n",
      "            1.4850e-02,  4.8284e-02],\n",
      "          [-6.0881e-02, -1.3131e+00, -6.0873e-01,  ...,  1.8584e-01,\n",
      "            3.6074e-01, -3.8274e-01],\n",
      "          [-9.6792e-01, -5.0507e-01, -6.3739e-01,  ...,  2.2335e+00,\n",
      "           -2.0287e-01,  2.6685e-01],\n",
      "          ...,\n",
      "          [ 9.9517e-03,  2.5716e-01, -4.7607e-01,  ..., -4.6717e-01,\n",
      "            2.2162e-01,  2.8081e-01],\n",
      "          [ 9.3107e-03,  2.5661e-01, -4.7514e-01,  ..., -4.6698e-01,\n",
      "            2.2376e-01,  2.7879e-01],\n",
      "          [ 7.9167e-03,  2.5629e-01, -4.7542e-01,  ..., -4.6504e-01,\n",
      "            2.2343e-01,  2.7928e-01]],\n",
      "\n",
      "         [[ 4.5020e-02,  4.0703e-02, -8.5913e-02,  ..., -2.0362e-03,\n",
      "           -1.8462e-02,  1.6405e-04],\n",
      "          [ 1.6720e-01,  4.8971e-01,  3.9579e-01,  ..., -2.8617e-03,\n",
      "           -6.2666e-01, -1.1864e+00],\n",
      "          [-1.1131e+00,  9.4846e-02, -1.8766e+00,  ..., -5.7526e-01,\n",
      "            1.2930e+00,  1.0208e-01],\n",
      "          ...,\n",
      "          [ 5.8741e-01, -5.8855e-02,  9.2873e-02,  ..., -1.1292e-01,\n",
      "           -6.2630e-01,  1.1984e-01],\n",
      "          [ 5.8765e-01, -6.0066e-02,  9.3414e-02,  ..., -1.1229e-01,\n",
      "           -6.2622e-01,  1.2039e-01],\n",
      "          [ 5.8680e-01, -6.0430e-02,  9.4048e-02,  ..., -1.1149e-01,\n",
      "           -6.2391e-01,  1.1891e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0052e-03,  3.0031e-02, -6.7098e-03,  ..., -2.2071e-02,\n",
      "           -2.5694e-02,  3.6145e-02],\n",
      "          [ 5.0417e-01,  1.1350e+00,  3.9957e-01,  ...,  5.8378e-02,\n",
      "           -1.8627e-01,  5.7473e-01],\n",
      "          [-4.1687e-01,  2.3248e+00,  9.0151e-01,  ..., -1.2137e-02,\n",
      "           -8.2568e-01, -2.4366e-01],\n",
      "          ...,\n",
      "          [ 3.9166e-01, -4.9965e-01,  5.6435e-01,  ...,  9.7567e-02,\n",
      "            2.0351e-03,  3.2788e-02],\n",
      "          [ 3.9143e-01, -5.0171e-01,  5.6430e-01,  ...,  9.7140e-02,\n",
      "            3.6097e-03,  3.2288e-02],\n",
      "          [ 3.9334e-01, -5.0402e-01,  5.6522e-01,  ...,  9.7912e-02,\n",
      "            2.3498e-03,  3.3469e-02]],\n",
      "\n",
      "         [[-6.5377e-02, -4.5243e-02,  2.9972e-02,  ...,  1.7289e-02,\n",
      "           -4.0501e-02, -1.0150e-01],\n",
      "          [ 3.3697e-01,  1.1677e-01, -8.0097e-01,  ...,  7.6041e-01,\n",
      "            1.3982e-01, -1.2177e-01],\n",
      "          [ 5.2790e-01, -8.1432e-01, -1.4104e+00,  ...,  1.0878e+00,\n",
      "           -4.1893e-01,  7.3349e-01],\n",
      "          ...,\n",
      "          [-2.1966e-01,  1.4382e-01,  3.7126e-02,  ..., -2.7149e-01,\n",
      "            5.8993e-01,  4.7534e-01],\n",
      "          [-2.2070e-01,  1.4290e-01,  3.8756e-02,  ..., -2.7205e-01,\n",
      "            5.8898e-01,  4.7514e-01],\n",
      "          [-2.1922e-01,  1.4348e-01,  3.8562e-02,  ..., -2.7356e-01,\n",
      "            5.8955e-01,  4.7442e-01]],\n",
      "\n",
      "         [[-1.1829e-02,  3.3011e-02, -4.7851e-02,  ..., -7.7910e-03,\n",
      "            1.3503e-02,  1.1945e-02],\n",
      "          [ 9.6118e-02, -3.9244e-01, -6.0998e-01,  ..., -1.6956e-01,\n",
      "            1.0601e+00, -3.7701e-01],\n",
      "          [-1.9933e+00,  1.7587e+00,  4.5875e-01,  ..., -1.3203e-01,\n",
      "            1.7841e-01,  3.2839e-01],\n",
      "          ...,\n",
      "          [-3.3208e-02, -5.9641e-02, -3.2627e-01,  ..., -9.8138e-02,\n",
      "            3.2601e-01, -1.0338e-01],\n",
      "          [-3.4120e-02, -5.8418e-02, -3.2664e-01,  ..., -9.4448e-02,\n",
      "            3.2484e-01, -1.0093e-01],\n",
      "          [-3.4084e-02, -5.7798e-02, -3.2468e-01,  ..., -9.4742e-02,\n",
      "            3.2369e-01, -1.0030e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.5105,  0.4888, -0.8554,  ..., -1.0267, -1.3161,  0.2115],\n",
      "          [ 0.2877,  1.1726,  0.3502,  ...,  1.8822,  0.3735, -1.5771],\n",
      "          [-1.6635,  1.6901,  0.2960,  ...,  0.3133,  0.8837, -1.0113],\n",
      "          ...,\n",
      "          [-0.0618,  1.3835, -0.9944,  ...,  1.7097, -0.7247,  0.0156],\n",
      "          [-0.0639,  1.3837, -0.9950,  ...,  1.7110, -0.7241,  0.0155],\n",
      "          [-0.0659,  1.3825, -0.9953,  ...,  1.7115, -0.7248,  0.0154]],\n",
      "\n",
      "         [[ 0.8641, -2.0632,  0.1507,  ...,  0.2358, -2.4628, -0.4365],\n",
      "          [ 0.9688,  2.2874,  0.0156,  ...,  0.7563,  1.3243,  0.4979],\n",
      "          [ 1.3873,  0.6857,  0.2313,  ...,  1.4202, -1.5294,  0.6578],\n",
      "          ...,\n",
      "          [ 0.5579, -0.5360, -0.0518,  ...,  1.5062, -2.2284, -1.1147],\n",
      "          [ 0.5586, -0.5323, -0.0526,  ...,  1.5066, -2.2283, -1.1140],\n",
      "          [ 0.5570, -0.5322, -0.0537,  ...,  1.5079, -2.2294, -1.1136]],\n",
      "\n",
      "         [[ 1.0047,  0.3677, -0.1759,  ..., -0.8085, -1.3894, -0.3705],\n",
      "          [-1.7129, -0.7999, -0.7384,  ...,  1.3115, -0.2055,  0.0450],\n",
      "          [-0.6748,  0.8466, -0.7017,  ...,  0.4244, -0.6545,  0.5466],\n",
      "          ...,\n",
      "          [ 0.4996,  0.4533, -0.4969,  ..., -0.8468, -2.2123, -0.6056],\n",
      "          [ 0.4999,  0.4535, -0.4953,  ..., -0.8486, -2.2136, -0.6068],\n",
      "          [ 0.5009,  0.4546, -0.4940,  ..., -0.8504, -2.2138, -0.6077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2270, -0.5682,  0.4831,  ..., -0.6640,  1.0591,  0.2766],\n",
      "          [-0.4265,  1.3822, -1.1272,  ..., -2.1121, -1.1342, -0.3716],\n",
      "          [-2.0286,  1.9592, -1.5740,  ..., -1.7630, -2.0098,  1.2917],\n",
      "          ...,\n",
      "          [-0.7283, -0.3468, -1.2720,  ..., -2.1449,  0.5128,  0.4386],\n",
      "          [-0.7160, -0.3478, -1.2811,  ..., -2.1439,  0.5130,  0.4396],\n",
      "          [-0.7024, -0.3498, -1.2880,  ..., -2.1416,  0.5149,  0.4379]],\n",
      "\n",
      "         [[ 0.2557,  0.5486,  0.5427,  ...,  0.7337,  0.0735,  0.8409],\n",
      "          [-0.2630,  3.1089,  0.0968,  ...,  1.1111, -1.2343,  0.9462],\n",
      "          [-2.6527,  1.1013, -0.4171,  ..., -0.5077,  0.6633,  0.9173],\n",
      "          ...,\n",
      "          [ 0.1849,  1.4512,  1.6386,  ...,  0.8705,  0.7537,  1.4136],\n",
      "          [ 0.1848,  1.4506,  1.6418,  ...,  0.8713,  0.7536,  1.4166],\n",
      "          [ 0.1841,  1.4500,  1.6421,  ...,  0.8730,  0.7521,  1.4173]],\n",
      "\n",
      "         [[-0.7236,  0.3119, -1.5837,  ..., -0.3841,  0.2253, -1.3224],\n",
      "          [-1.1716, -0.2108, -0.5625,  ..., -1.0099,  0.2504,  0.5097],\n",
      "          [ 0.2962, -0.3649, -1.4734,  ..., -0.8229,  0.2748,  1.0291],\n",
      "          ...,\n",
      "          [-0.4965, -0.0887,  0.0205,  ...,  0.7125,  1.0578, -0.9382],\n",
      "          [-0.4988, -0.0892,  0.0219,  ...,  0.7140,  1.0576, -0.9373],\n",
      "          [-0.4980, -0.0915,  0.0221,  ...,  0.7146,  1.0585, -0.9377]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 1.8846e-02,  4.6500e-02, -6.7226e-02,  ...,  6.0935e-02,\n",
      "           -2.3287e-02, -9.3406e-02],\n",
      "          [-9.4938e-01, -7.0013e-01,  1.5670e+00,  ..., -7.2562e-01,\n",
      "           -3.4044e-01,  7.6453e-02],\n",
      "          [-5.0993e-01, -1.3658e+00,  7.2385e-01,  ..., -2.3836e-01,\n",
      "           -1.9181e-01,  1.3572e+00],\n",
      "          ...,\n",
      "          [ 2.3283e-01,  1.1082e-01,  2.9416e-01,  ...,  2.2395e-01,\n",
      "            6.6861e-02,  7.5684e-02],\n",
      "          [ 2.3313e-01,  1.0798e-01,  2.9311e-01,  ...,  2.2396e-01,\n",
      "            6.7475e-02,  7.5337e-02],\n",
      "          [ 2.3355e-01,  1.0849e-01,  2.9263e-01,  ...,  2.2498e-01,\n",
      "            6.6159e-02,  7.5047e-02]],\n",
      "\n",
      "         [[ 5.9533e-02,  7.3230e-04,  3.6023e-02,  ..., -3.3076e-02,\n",
      "           -2.6139e-02, -2.8996e-03],\n",
      "          [ 7.9582e-01, -4.8593e-02, -4.5048e-02,  ...,  2.7073e-01,\n",
      "            3.3371e-01,  7.6484e-01],\n",
      "          [-6.8048e-01, -7.0597e-02, -9.5564e-02,  ...,  1.0895e+00,\n",
      "            8.2613e-01,  7.0866e-01],\n",
      "          ...,\n",
      "          [ 3.1148e-02,  7.1047e-02,  3.9073e-01,  ...,  1.3327e-01,\n",
      "           -1.7582e-01, -1.1425e-01],\n",
      "          [ 2.9920e-02,  6.9098e-02,  3.9122e-01,  ...,  1.3471e-01,\n",
      "           -1.7511e-01, -1.1345e-01],\n",
      "          [ 2.8965e-02,  6.6429e-02,  3.8951e-01,  ...,  1.3465e-01,\n",
      "           -1.7406e-01, -1.1453e-01]],\n",
      "\n",
      "         [[-1.0822e-02,  1.1039e-02, -2.9605e-02,  ...,  1.4061e-02,\n",
      "            3.5705e-02,  5.5029e-02],\n",
      "          [ 2.8249e-02,  1.3149e-01,  6.0443e-01,  ...,  2.2485e-01,\n",
      "           -9.9926e-01, -2.6869e-01],\n",
      "          [ 4.5143e-01, -1.3891e+00, -8.3870e-01,  ..., -1.3061e+00,\n",
      "           -9.8043e-01,  3.7741e-01],\n",
      "          ...,\n",
      "          [ 1.9335e-01,  2.6984e-01,  1.7417e-01,  ...,  4.4807e-01,\n",
      "           -5.8217e-02, -4.1246e-01],\n",
      "          [ 1.9274e-01,  2.7084e-01,  1.7352e-01,  ...,  4.4856e-01,\n",
      "           -5.8870e-02, -4.1326e-01],\n",
      "          [ 1.9035e-01,  2.7096e-01,  1.7232e-01,  ...,  4.4847e-01,\n",
      "           -5.9990e-02, -4.1299e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.8938e-02,  3.7375e-02, -1.7195e-03,  ..., -4.7671e-02,\n",
      "           -2.1496e-02,  2.7531e-02],\n",
      "          [ 1.6518e-01,  7.4135e-01, -7.2497e-01,  ...,  2.1972e-01,\n",
      "           -4.6067e-01,  1.2030e-01],\n",
      "          [-2.2794e-01,  7.2284e-01,  4.0015e-01,  ...,  1.4945e+00,\n",
      "           -1.5510e-01, -3.3880e-02],\n",
      "          ...,\n",
      "          [-1.2155e-01,  8.6418e-02,  4.3140e-01,  ..., -5.1327e-02,\n",
      "           -5.9375e-01,  4.5298e-02],\n",
      "          [-1.2146e-01,  8.5531e-02,  4.3121e-01,  ..., -5.0714e-02,\n",
      "           -5.9585e-01,  4.5646e-02],\n",
      "          [-1.2191e-01,  8.5177e-02,  4.3061e-01,  ..., -5.0704e-02,\n",
      "           -5.9661e-01,  4.5040e-02]],\n",
      "\n",
      "         [[ 8.4550e-02,  2.7683e-02,  6.4263e-02,  ...,  2.7156e-02,\n",
      "            4.6119e-02,  9.7696e-03],\n",
      "          [-6.1208e-01,  3.6774e-01,  5.9525e-01,  ..., -2.3135e+00,\n",
      "            6.9887e-01, -1.3180e+00],\n",
      "          [-3.2863e-01, -2.0699e+00, -8.0602e-02,  ...,  1.8025e+00,\n",
      "           -3.7591e-01, -7.1462e-02],\n",
      "          ...,\n",
      "          [ 8.2289e-02,  1.1209e+00,  1.1094e+00,  ...,  7.4733e-02,\n",
      "            3.8067e-01, -2.4234e-01],\n",
      "          [ 8.1204e-02,  1.1229e+00,  1.1127e+00,  ...,  7.5736e-02,\n",
      "            3.8091e-01, -2.4050e-01],\n",
      "          [ 8.0842e-02,  1.1251e+00,  1.1131e+00,  ...,  7.6519e-02,\n",
      "            3.7927e-01, -2.3953e-01]],\n",
      "\n",
      "         [[-1.1082e-01,  2.3628e-02, -5.7385e-02,  ..., -9.5812e-02,\n",
      "            5.7014e-02, -1.9716e-02],\n",
      "          [ 1.0451e+00,  1.6790e-01, -2.4514e-01,  ...,  7.5939e-01,\n",
      "            1.0304e+00,  7.7789e-01],\n",
      "          [ 1.1043e+00,  7.3407e-01,  5.5769e-01,  ..., -1.4399e-01,\n",
      "            2.4517e+00,  4.2931e-01],\n",
      "          ...,\n",
      "          [-1.7405e-01, -6.6514e-02, -2.9103e-01,  ..., -7.0869e-01,\n",
      "            8.1334e-02,  2.0099e-01],\n",
      "          [-1.7442e-01, -6.7635e-02, -2.9072e-01,  ..., -7.0880e-01,\n",
      "            8.1002e-02,  2.0039e-01],\n",
      "          [-1.7535e-01, -6.7649e-02, -2.9123e-01,  ..., -7.0837e-01,\n",
      "            7.9448e-02,  1.9940e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7216, -0.3013, -0.2952,  ...,  0.1865,  0.3256, -0.5023],\n",
      "          [-0.1957, -0.1786, -0.9112,  ...,  1.1172, -0.7191, -0.0284],\n",
      "          [ 0.2893,  0.0334, -0.7149,  ...,  1.7928, -0.5917, -0.5108],\n",
      "          ...,\n",
      "          [ 1.5653, -1.5883, -0.7207,  ...,  1.1809, -1.5205,  0.0072],\n",
      "          [ 1.5658, -1.5900, -0.7204,  ...,  1.1799, -1.5241,  0.0076],\n",
      "          [ 1.5662, -1.5907, -0.7210,  ...,  1.1804, -1.5271,  0.0061]],\n",
      "\n",
      "         [[ 0.1073, -0.0800,  2.2955,  ...,  0.2432,  0.0857, -0.1948],\n",
      "          [ 0.9808, -0.6278, -0.4527,  ...,  0.3213,  0.1807, -0.0346],\n",
      "          [ 0.3079, -1.4687, -1.0998,  ...,  0.6513,  0.2474, -0.3724],\n",
      "          ...,\n",
      "          [ 0.4461, -0.9798, -0.2748,  ...,  0.1383,  0.5660, -1.0238],\n",
      "          [ 0.4452, -0.9812, -0.2783,  ...,  0.1391,  0.5672, -1.0238],\n",
      "          [ 0.4462, -0.9829, -0.2794,  ...,  0.1406,  0.5677, -1.0235]],\n",
      "\n",
      "         [[-0.1928,  1.0482,  0.4753,  ..., -0.5411,  0.3269, -0.1044],\n",
      "          [-0.1273,  0.0276, -0.0614,  ...,  1.1025,  0.4218, -0.4889],\n",
      "          [-0.7566,  0.4478,  0.9743,  ...,  0.5001,  0.0682, -1.3117],\n",
      "          ...,\n",
      "          [ 0.0380,  1.1097, -0.1094,  ...,  1.1001,  0.7060, -0.6905],\n",
      "          [ 0.0384,  1.1108, -0.1070,  ...,  1.1025,  0.7046, -0.6891],\n",
      "          [ 0.0401,  1.1103, -0.1054,  ...,  1.1037,  0.7041, -0.6882]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.5510,  0.9702, -0.8676,  ..., -0.7088,  0.6934,  0.8508],\n",
      "          [-0.1047,  0.5283, -1.5482,  ..., -0.6607, -0.7164,  0.1849],\n",
      "          [ 0.7032,  0.7297,  0.5154,  ...,  0.0840, -1.4286,  0.2348],\n",
      "          ...,\n",
      "          [ 0.9141,  0.6289, -0.5234,  ..., -0.8406,  0.5928,  0.5276],\n",
      "          [ 0.9122,  0.6263, -0.5225,  ..., -0.8388,  0.5921,  0.5266],\n",
      "          [ 0.9105,  0.6244, -0.5215,  ..., -0.8387,  0.5921,  0.5252]],\n",
      "\n",
      "         [[-0.4068,  0.3957,  0.3603,  ...,  0.6988,  0.0296, -0.0826],\n",
      "          [-1.4076,  1.4544, -1.0819,  ...,  0.3654, -0.2819, -0.1160],\n",
      "          [-1.3450,  1.6842, -1.4639,  ...,  1.2783,  0.6836, -0.0600],\n",
      "          ...,\n",
      "          [-1.2393,  1.4681, -1.9694,  ..., -0.1456,  0.0144, -1.2331],\n",
      "          [-1.2404,  1.4699, -1.9723,  ..., -0.1483,  0.0163, -1.2357],\n",
      "          [-1.2407,  1.4705, -1.9743,  ..., -0.1509,  0.0176, -1.2363]],\n",
      "\n",
      "         [[-0.7434, -0.0046,  0.4467,  ..., -0.1008,  0.0175, -0.0680],\n",
      "          [ 0.7038, -0.6238,  0.3741,  ..., -0.4137, -1.0309,  1.0379],\n",
      "          [-1.0439, -0.5250,  0.5126,  ..., -0.1433, -0.6020,  2.6223],\n",
      "          ...,\n",
      "          [-1.3076, -2.6856,  3.8098,  ...,  2.4266,  2.7382,  2.1658],\n",
      "          [-1.3085, -2.6852,  3.8091,  ...,  2.4271,  2.7378,  2.1679],\n",
      "          [-1.3095, -2.6854,  3.8081,  ...,  2.4266,  2.7408,  2.1692]]]],\n",
      "       grad_fn=<PermuteBackward0>), tensor([[[[ 1.0645e-01, -1.2225e-01, -1.5623e-01,  ..., -2.6699e-01,\n",
      "            2.4492e-01, -1.4057e-01],\n",
      "          [ 1.4053e+00,  1.1910e-01,  3.3127e-01,  ...,  3.0563e+00,\n",
      "           -1.4882e+00,  1.4536e+00],\n",
      "          [ 9.3619e-01,  5.0588e-01,  9.3833e-01,  ...,  2.3259e+00,\n",
      "           -1.2517e+00,  1.2221e+00],\n",
      "          ...,\n",
      "          [-3.5968e-01, -2.0665e-01,  1.9707e+00,  ...,  1.9450e+00,\n",
      "           -3.4721e-01,  1.2286e+00],\n",
      "          [-3.5806e-01, -2.0660e-01,  1.9694e+00,  ...,  1.9432e+00,\n",
      "           -3.4908e-01,  1.2305e+00],\n",
      "          [-3.5988e-01, -2.0655e-01,  1.9688e+00,  ...,  1.9433e+00,\n",
      "           -3.4614e-01,  1.2296e+00]],\n",
      "\n",
      "         [[ 1.2369e-01, -4.3063e-02,  1.9401e-02,  ..., -2.6137e-02,\n",
      "           -9.1657e-02,  1.6585e-01],\n",
      "          [ 1.6225e-02, -7.6139e-02, -3.0626e-01,  ...,  3.6312e-01,\n",
      "            3.1141e-01, -7.9515e-01],\n",
      "          [-1.3517e+00,  1.2059e+00, -1.4013e+00,  ...,  1.6044e+00,\n",
      "            2.9457e-01,  5.2310e-01],\n",
      "          ...,\n",
      "          [ 4.0906e-01, -2.5058e-01,  7.8989e-02,  ...,  8.5109e-01,\n",
      "           -1.6504e-01,  1.9094e-01],\n",
      "          [ 4.0787e-01, -2.5122e-01,  7.9574e-02,  ...,  8.5140e-01,\n",
      "           -1.6680e-01,  1.9135e-01],\n",
      "          [ 4.0632e-01, -2.5190e-01,  8.1245e-02,  ...,  8.5174e-01,\n",
      "           -1.6683e-01,  1.9224e-01]],\n",
      "\n",
      "         [[-1.6392e-02,  3.4660e-02, -6.6968e-02,  ...,  2.9037e-02,\n",
      "            1.4987e-02,  6.8483e-02],\n",
      "          [ 1.5384e+00,  1.3917e+00,  9.1239e-01,  ..., -3.7864e-01,\n",
      "            4.2572e-02,  4.8156e-01],\n",
      "          [-8.2337e-01, -1.2314e+00,  1.6316e+00,  ...,  1.6281e+00,\n",
      "           -4.9637e-01,  5.7304e-01],\n",
      "          ...,\n",
      "          [-2.9115e-03, -1.9505e-01, -7.2600e-01,  ...,  3.0606e-01,\n",
      "            5.3698e-01, -5.4192e-01],\n",
      "          [-3.7715e-03, -1.9547e-01, -7.2583e-01,  ...,  3.0841e-01,\n",
      "            5.3626e-01, -5.4341e-01],\n",
      "          [-4.4207e-03, -1.9402e-01, -7.2598e-01,  ...,  3.0813e-01,\n",
      "            5.3671e-01, -5.4415e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.8944e-03, -1.1060e-02,  9.8767e-02,  ...,  8.3782e-02,\n",
      "           -2.1197e-02,  4.7787e-02],\n",
      "          [-4.0697e-01,  7.7852e-01,  7.2391e-01,  ...,  9.6797e-01,\n",
      "           -8.0065e-02,  2.7626e-01],\n",
      "          [-1.0635e+00,  1.3665e+00,  1.1858e+00,  ...,  5.4896e-01,\n",
      "           -9.9051e-01,  2.9212e-01],\n",
      "          ...,\n",
      "          [-1.6210e-01,  3.0224e-01,  3.7683e-01,  ...,  1.1659e-01,\n",
      "            4.6959e-02,  3.7566e-02],\n",
      "          [-1.6171e-01,  3.0252e-01,  3.7535e-01,  ...,  1.1521e-01,\n",
      "            4.5681e-02,  3.7001e-02],\n",
      "          [-1.6249e-01,  3.0243e-01,  3.7553e-01,  ...,  1.1525e-01,\n",
      "            4.4827e-02,  3.7458e-02]],\n",
      "\n",
      "         [[-1.9653e-01, -6.4690e-02,  6.6298e-02,  ..., -4.5616e-02,\n",
      "            4.9265e-02, -8.1526e-02],\n",
      "          [-8.7624e-01,  2.0199e-01, -3.4553e-01,  ...,  2.2088e-01,\n",
      "            7.5964e-01, -1.4984e-01],\n",
      "          [-6.2712e-01,  9.3119e-02, -6.8328e-01,  ..., -8.1139e-01,\n",
      "           -7.5163e-01, -4.2854e-01],\n",
      "          ...,\n",
      "          [-4.7730e-01,  3.9406e-01,  6.4905e-01,  ..., -3.7173e-01,\n",
      "            4.4251e-01,  1.0700e-01],\n",
      "          [-4.7816e-01,  3.9460e-01,  6.5022e-01,  ..., -3.7342e-01,\n",
      "            4.4276e-01,  1.0922e-01],\n",
      "          [-4.7686e-01,  3.9458e-01,  6.5047e-01,  ..., -3.7376e-01,\n",
      "            4.4320e-01,  1.1065e-01]],\n",
      "\n",
      "         [[ 1.0403e-01, -1.4689e-01,  1.7522e-01,  ..., -1.5280e-01,\n",
      "            4.9775e-03, -1.8157e-01],\n",
      "          [-5.4245e-01, -4.9021e-01,  1.4413e+00,  ..., -7.5504e-01,\n",
      "            1.6870e-01, -1.9359e-02],\n",
      "          [-1.7719e-01,  4.6683e-01,  5.6569e-01,  ..., -2.8442e-01,\n",
      "            7.3781e-01,  6.7927e-01],\n",
      "          ...,\n",
      "          [ 7.4035e-01,  1.5697e+00, -2.3163e+00,  ...,  3.4021e+00,\n",
      "            1.3654e+00,  5.2201e-01],\n",
      "          [ 7.4067e-01,  1.5707e+00, -2.3152e+00,  ...,  3.4037e+00,\n",
      "            1.3649e+00,  5.2111e-01],\n",
      "          [ 7.4138e-01,  1.5710e+00, -2.3156e+00,  ...,  3.4038e+00,\n",
      "            1.3657e+00,  5.1972e-01]]]], grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, GPT2LMHeadModel\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Load the dataset (assuming dataset is already loaded as 'dataset')\n",
    "# Example: dataset = load_dataset(\"csv\", data_files={\"train\": \"train.csv\", \"test\": \"test.csv\"})\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_dict({\n",
    "        \"prompt\": [\"What is AI?\", \"What is the capital of France?\"],\n",
    "        \"completion\": [\"AI stands for Artificial Intelligence.\", \"The capital of France is Paris.\"]\n",
    "    }),\n",
    "    \"test\": Dataset.from_dict({\n",
    "        \"prompt\": [\"What is Python?\", \"What is machine learning?\"],\n",
    "        \"completion\": [\"Python is a programming language.\", \"Machine learning is a subset of AI.\"]\n",
    "    })\n",
    "})\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set padding token to EOS token\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    prompts = examples[\"prompt\"]\n",
    "    completions = examples[\"completion\"]\n",
    "    \n",
    "    # Concatenate prompt and completion and tokenize them\n",
    "    full_texts = [prompt + tokenizer.eos_token + completion for prompt, completion in zip(prompts, completions)]\n",
    "    \n",
    "    # Tokenize batch and ensure padding/truncation\n",
    "    tokenized_batch = tokenizer(\n",
    "        full_texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # Ensure all are padded to the max length\n",
    "        max_length=128,        # Adjust the max length as needed\n",
    "        return_tensors=\"pt\"    # Return as pytorch tensors\n",
    "    )\n",
    "    \n",
    "    return tokenized_batch\n",
    "\n",
    "# Apply tokenization on dataset\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"prompt\", \"completion\"]  # Remove original text columns after tokenization\n",
    ")\n",
    "\n",
    "# Manually split the 'train' data into train, validation, and test sets\n",
    "train_dataset = tokenized_dataset[\"train\"].select(range(0, 1))  # Example split: 70% for training\n",
    "val_dataset = tokenized_dataset[\"train\"].select(range(1, 2))    # Example split: 15% for validation\n",
    "test_dataset = tokenized_dataset[\"test\"].select(range(0, 1))    # Example split: 15% for testing\n",
    "\n",
    "# Create a DatasetDict\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "# Check sequence lengths for consistency between input_ids and attention_mask\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    for idx in range(len(split_dataset[split])):\n",
    "        example = split_dataset[split][idx]  # Access the example by index\n",
    "        \n",
    "        # Check if 'input_ids' and 'attention_mask' are lists\n",
    "        if isinstance(example['input_ids'], list) and isinstance(example['attention_mask'], list):\n",
    "            input_len = len(example['input_ids'])\n",
    "            attention_len = len(example['attention_mask'])\n",
    "            if input_len != attention_len:\n",
    "                print(f\"Inconsistent length at index {idx} in {split} split: input_ids={input_len}, attention_mask={attention_len}\")\n",
    "        else:\n",
    "            print(f\"Invalid data at index {idx} in {split} split: input_ids type={type(example['input_ids'])}, attention_mask type={type(example['attention_mask'])}\")\n",
    "\n",
    "# Define a data collator for language modeling (for causal models like GPT-2)\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False  # Masked language modeling is False for causal models like GPT-2\n",
    ")\n",
    "\n",
    "# Convert the tokenized dataset to a PyTorch-friendly format\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "validation_dataset = split_dataset[\"validation\"]\n",
    "test_dataset = split_dataset[\"test\"]\n",
    "\n",
    "# Print final datasets to check if the changes worked\n",
    "print(train_dataset[0])  # Check the first training sample\n",
    "print(validation_dataset[0])  # Check the first validation sample\n",
    "print(test_dataset[0])  # Check the first testing sample\n",
    "\n",
    "# Optionally, load a GPT-2 model for fine-tuning (you can skip this part if not fine-tuning)\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "\n",
    "input_ids = torch.tensor(train_dataset[0]['input_ids'])\n",
    "attention_mask = torch.tensor(train_dataset[0]['attention_mask'])\n",
    "\n",
    "# Apply unsqueeze to add the batch dimension\n",
    "output = model(input_ids=input_ids.unsqueeze(0), attention_mask=attention_mask.unsqueeze(0))\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2204fc1-6f9c-40bb-80ce-8a1b22c09fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd8c701b-8fae-4b5c-a2c3-ffaf8a76e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 9.5173\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.8011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 7.4628\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 6.7323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.2942\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 4.6647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.6678\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 3.2459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.4349\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.6124\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.0473\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6694\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4585\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|█████████████████████████████████| 1/1 [00:00<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|████████████████████████████████████| 1/1 [00:00<00:00, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW, GPT2LMHeadModel, AutoTokenizer\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the dataset and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "# DataLoader: Prepare the DataLoader for batching the tokenized dataset\n",
    "train_dataset = split_dataset['train']\n",
    "validation_dataset = split_dataset['validation']\n",
    "test_dataset = split_dataset['test']\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2)\n",
    "\n",
    "# Move model to GPU (if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set up the optimizer (AdamW is a good choice for transformers)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define the training loop\n",
    "def train(model, train_dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(batch['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
    "\n",
    "        # Forward pass: Compute logits and loss\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss  # The loss is returned as a tuple, with the first element being the loss\n",
    "\n",
    "        # Backward pass: Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients to avoid exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Return the average loss for the epoch\n",
    "    return total_loss / len(train_dataloader)\n",
    "\n",
    "# Define the validation loop\n",
    "def validate(model, validation_dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validation_dataloader, desc=\"Validating\"):\n",
    "            # Convert lists to tensors\n",
    "            input_ids = torch.tensor(batch['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
    "\n",
    "            # Forward pass: Compute logits and loss\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    # Return the average loss for the validation\n",
    "    return total_loss / len(validation_dataloader)\n",
    "\n",
    "# Define the testing loop\n",
    "def test(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "            # Convert lists to tensors\n",
    "            input_ids = torch.tensor(batch['input_ids']).to(device)\n",
    "            attention_mask = torch.tensor(batch['attention_mask']).to(device)\n",
    "\n",
    "            # Forward pass: Compute logits and loss\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_dataloader)\n",
    "\n",
    "# Training and evaluation loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Train the model\n",
    "    train_loss = train(model, train_dataloader, optimizer, device)\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Validate the model\n",
    "    val_loss = validate(model, validation_dataloader, device)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save the model after every epoch\n",
    "    torch.save(model.state_dict(), f\"gpt2_finetuned_epoch_{epoch+1}.pth\")\n",
    "\n",
    "# Optionally, test the model on the test dataset\n",
    "test_loss = test(model, test_dataloader, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fbaa43e-9641-4980-8738-f203f6f32483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_gpt2/tokenizer_config.json',\n",
       " './fine_tuned_gpt2/special_tokens_map.json',\n",
       " './fine_tuned_gpt2/vocab.json',\n",
       " './fine_tuned_gpt2/merges.txt',\n",
       " './fine_tuned_gpt2/added_tokens.json',\n",
       " './fine_tuned_gpt2/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./fine_tuned_gpt2\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adbb3fa8-4dda-4a78-a953-bd1e71f6d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to ./fine_tuned_model\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "output_dir = \"./fine_tuned_model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcec0b9c-07b5-48c4-a96e-523a1c1e4b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "# Load the fine-tuned model\n",
    "output_dir = \"./fine_tuned_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = GPT2LMHeadModel.from_pretrained(output_dir)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7305be2c-80b4-4134-af0d-24f19f1f812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output: what is calisnova? and a final one that is at the same time different for this kind of thing and not even the original one) I hope people will try them with different styles.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"what is calisnova?\"\n",
    "\n",
    "# Encode the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate attention mask\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long)\n",
    "\n",
    "# Set pad_token_id to eos_token_id if not defined\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Generate output with adjusted parameters\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=150,  # Increase tokens for more elaborate response\n",
    "    temperature=1.2,  # Adjust for more creativity\n",
    "    top_p=0.9,  # Use nucleus sampling for more diversity\n",
    "    top_k=50,  # Use top-k sampling\n",
    "    do_sample=True,  # Enable sampling\n",
    "    no_repeat_ngram_size=2  # Prevent repetition\n",
    ")\n",
    "\n",
    "# Decode and print the output\n",
    "generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"Generated Output:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad30d5e-2ac1-4a47-a756-1c55b2368184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./finetuned_model/tokenizer_config.json',\n",
       " './finetuned_model/special_tokens_map.json',\n",
       " './finetuned_model/vocab.json',\n",
       " './finetuned_model/merges.txt',\n",
       " './finetuned_model/added_tokens.json',\n",
       " './finetuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained('./finetuned_model')\n",
    "tokenizer.save_pretrained('./finetuned_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959baec6-6bd9-4344-94a2-962d6e78d328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
